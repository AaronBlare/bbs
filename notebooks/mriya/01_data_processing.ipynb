{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:22.801727Z",
     "start_time": "2024-07-01T14:29:18.695223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from sklearn.model_selection import BaseCrossValidator, ParameterGrid, ParameterSampler\n",
    "import torch\n",
    "import pickle\n",
    "import shutil\n",
    "from scipy import stats\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "from src.utils.hash import dict_hash\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import distinctipy\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.colors as mcolors\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.plots import bar\n",
    "from plottable.cmap import normed_cmap, centered_cmap\n",
    "import optuna\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.cm\n",
    "import matplotlib as mpl\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import re\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, bg_rgb)]\n",
    "\n",
    "def form_bar(base):\n",
    "    def formatter(x):\n",
    "        return f'{str(int(round(x * base)))}/{base}'\n",
    "    return formatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"D:/YandexDisk/Work/bbd/mriya\"\n",
    "\n",
    "yadisk_file_url = \"https://disk.yandex.ru/i/CEaw3cqI2Y7J0A\"\n",
    "response = requests.get(\n",
    "    \"https://cloud-api.yandex.net/v1/disk/public/resources/download\", \n",
    "    params={'public_key': yadisk_file_url}\n",
    ")\n",
    "res = response.json()\n",
    "download_url = res['href']\n",
    "response = requests.get(download_url)\n",
    "yadisk_subject_file_name = Path(f\"{path}/Испытуемые Яндекс.xlsx\")\n",
    "with open(yadisk_subject_file_name, 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params = pd.read_excel(f\"{path}/Испытуемые Яндекс.xlsx\", sheet_name='Parameters', index_col=0)\n",
    "df_blood = pd.read_excel(f\"{path}/Испытуемые Яндекс.xlsx\", sheet_name='Blood', index_col=0)\n",
    "df_heart = pd.read_excel(f\"{path}/Испытуемые Яндекс.xlsx\", sheet_name='Heart', index_col=0)\n",
    "df_blood.insert(3, 'Age', (df_blood['sample_date'] - df_blood['birthday']) / np.timedelta64(1, 'D') / 365.25)\n",
    "df_heart.insert(3, 'Age', (df_heart['sample_date'] - df_heart['birthday']) / np.timedelta64(1, 'D') / 365.25)\n",
    "\n",
    "suffixes=('', '_heart')\n",
    "df = pd.merge(df_blood, df_heart, left_index=True, right_index=True, how='outer', suffixes=suffixes)\n",
    "cols_cmn = df_blood.columns.intersection(df_heart.columns).to_list()\n",
    "with pd.ExcelWriter(f\"{path}/conflicts.xlsx\", engine='xlsxwriter') as writer:\n",
    "    for col in cols_cmn:\n",
    "        non_eq_ids = df.index[df[f'{col}{suffixes[0]}'] != df[f'{col}{suffixes[1]}']].to_list()\n",
    "        df_col = df.loc[non_eq_ids, [f'{col}{suffixes[0]}', f'{col}{suffixes[1]}']]\n",
    "        df_col.rename(columns={f'{col}{suffixes[0]}': 'Blood', f'{col}{suffixes[1]}': 'Heart'}, inplace=True)\n",
    "        df_col.to_excel(writer, sheet_name=col)\n",
    "        \n",
    "cols_types = df_params['analysis_type'].dropna().unique()\n",
    "cols_sets = {x: df.columns.intersection(df_params.index[df_params['analysis_type'] == x]).to_list() for x in cols_types}\n",
    "df = df.loc[:, cols_cmn + list(chain.from_iterable(cols_sets.values()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaNs analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f\"{path}/nans.xlsx\", engine='xlsxwriter') as writer:\n",
    "    for col_set, cols in cols_sets.items():\n",
    "        data = df.loc[:, cols]\n",
    "        nan_feats = data.isna().sum(axis=0).to_frame(name=\"Number of NaNs\")\n",
    "        nan_feats[\"% of NaNs\"] = nan_feats[\"Number of NaNs\"] / data.shape[0] * 100\n",
    "        nan_feats[\"Number of not-NaNs\"] = data.notna().sum(axis=0)\n",
    "        nan_feats.sort_values([\"% of NaNs\"], ascending=[True], inplace=True)\n",
    "        nan_feats.to_excel(writer, sheet_name=col_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation with Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_bins = np.linspace(5, 115, 23)\n",
    "sns.set_theme(style='ticks')\n",
    "fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "histplot = sns.histplot(\n",
    "    data=df[['Age']].dropna(),\n",
    "    bins=hist_bins,\n",
    "    edgecolor='k',\n",
    "    linewidth=1,\n",
    "    x=\"Age\",\n",
    "    color='crimson',\n",
    "    ax=ax\n",
    ")\n",
    "histplot.set(xlim=(0, 120))\n",
    "plt.savefig(f\"{path}/age_hist.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/age_hist.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "\n",
    "feats_cnt = df_params.index[df_params['data_type'].isin(['decimal', 'integer'])].intersection(list(chain.from_iterable(cols_sets.values()))).to_list()\n",
    "df_corr = pd.DataFrame(index=feats_cnt, columns=['count', 'rho', 'pval', ])\n",
    "for f in tqdm(feats_cnt):\n",
    "    df_tmp = df.loc[:, ['Age', f]].dropna(axis=0, how='any')\n",
    "    if df_tmp.shape[0] > 1:\n",
    "        df_corr.at[f, 'count'] = df_tmp.shape[0]\n",
    "        vals_1 = df_tmp.loc[:, 'Age'].values\n",
    "        vals_2 = df_tmp.loc[:, f].values\n",
    "        df_corr.at[f, 'rho'], df_corr.at[f, 'pval'] = stats.pearsonr(vals_1, vals_2)\n",
    "df_corr.dropna(axis=0, how='any', inplace=True)\n",
    "_, df_corr['pval_fdr_bh'], _, _ = multipletests(df_corr.loc[:, 'pval'].values, 0.05, method='fdr_bh')\n",
    "df_corr.insert(1, \"abs(rho)\", df_corr['rho'].abs())\n",
    "df_corr.sort_values([\"abs(rho)\"], ascending=[False], inplace=True)\n",
    "df_corr[['feature_name_ru', 'analysis_type', 'description']] = df_params.loc[df_corr.index, ['feature_name_ru', 'analysis_type', 'description']]\n",
    "df_corr.to_excel(f\"{path}/age_pearson.xlsx\", index_label=\"Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_sets = {\n",
    "    'Echocardiography': ['Echocardiography'],\n",
    "    'Sphygmocardiography': ['Sphygmocardiography'],\n",
    "    'BP': ['BP'],\n",
    "    'ECG': ['ECG'],\n",
    "    'Anthropometry': ['Anthropometry'],\n",
    "    'CBC': ['CBC'],\n",
    "}\n",
    "\n",
    "for fs, fls in feats_sets.items():\n",
    "    Path(f\"{path}/{fs}\").mkdir(parents=True, exist_ok=True)\n",
    "    feats = ['sex']\n",
    "    for fl in fls:\n",
    "        feats += pd.read_excel(f\"{path}/feats_cand.xlsx\", sheet_name=fl, index_col=0).index.to_list()\n",
    "    dataset_feats = df_params.loc[feats, :]\n",
    "    dataset_feats.to_excel(f\"{path}/{fs}/feats.xlsx\", index_label=\"Features\")\n",
    "    dataset_df = df[['Age'] + feats]\n",
    "    dataset_df.dropna(axis=0, how='any', inplace=True)\n",
    "    dataset_df.to_excel(f\"{path}/{fs}/data.xlsx\", index_label=\"IDs\")\n",
    "    \n",
    "    feats_cnt = ['Age'] + df_params.index[df_params['data_type'].isin(['decimal', 'integer'])].intersection(feats).to_list()\n",
    "    df_corr = pd.DataFrame(data=np.zeros(shape=(len(feats_cnt), len(feats_cnt))), index=feats_cnt, columns=feats_cnt)\n",
    "    for f_id_1 in range(len(feats_cnt)):\n",
    "        for f_id_2 in range(f_id_1, len(feats_cnt)):\n",
    "            f_1 = feats_cnt[f_id_1]\n",
    "            f_2 = feats_cnt[f_id_2]\n",
    "            if f_id_1 != f_id_2:\n",
    "                vals_1 = dataset_df.loc[:, f_1].values\n",
    "                vals_2 = dataset_df.loc[:, f_2].values\n",
    "                corr, pval = stats.pearsonr(vals_1, vals_2)\n",
    "                df_corr.at[f_2, f_1] = pval\n",
    "                df_corr.at[f_1, f_2] = corr\n",
    "            else:\n",
    "                df_corr.at[f_2, f_1] = np.nan\n",
    "    selection = np.tri(df_corr.shape[0], df_corr.shape[1], -1, dtype=bool)\n",
    "    df_fdr = df_corr.where(selection).stack().reset_index()\n",
    "    df_fdr.columns = ['row', 'col', 'pval']\n",
    "    _, df_fdr['pval_fdr_bh'], _, _ = multipletests(df_fdr.loc[:, 'pval'].values, 0.05, method='fdr_bh')\n",
    "    nzmin = df_fdr['pval_fdr_bh'][df_fdr['pval_fdr_bh'].gt(0)].min(0) * 0.5\n",
    "    df_fdr['pval_fdr_bh'].replace({0.0: nzmin}, inplace=True)\n",
    "    df_corr_fdr = df_corr.copy()\n",
    "    for line_id in range(df_fdr.shape[0]):\n",
    "        df_corr_fdr.loc[df_fdr.at[line_id, 'row'], df_fdr.at[line_id, 'col']] = -np.log10(df_fdr.at[line_id, 'pval_fdr_bh'])\n",
    "    df_corr_fdr.to_excel(f\"{path}/{fs}/feats_pearsonr.xlsx\")\n",
    "        \n",
    "    sns.set_theme(style='ticks')\n",
    "    fig, ax = plt.subplots(figsize=(4.5 + 0.25 * len(feats_cnt), 2.5 + 0.25 * len(feats_cnt)))\n",
    "    cmap_triu = plt.get_cmap(\"seismic\").copy()\n",
    "    mask_triu=np.tri(len(feats_cnt), len(feats_cnt), -1, dtype=bool)\n",
    "    heatmap_diff = sns.heatmap(\n",
    "        df_corr_fdr,\n",
    "        mask=mask_triu,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        center=0.0,\n",
    "        cmap=cmap_triu,\n",
    "        linewidth=0.1,\n",
    "        linecolor='black',\n",
    "        annot_kws={\"size\": 5},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.figure.axes[-1].set_ylabel(r\"Pearson $\\rho$\", size=13)\n",
    "    for spine in ax.figure.axes[-1].spines.values():\n",
    "        spine.set(visible=True, lw=0.25, edgecolor=\"black\")\n",
    "        \n",
    "    cmap_tril = plt.get_cmap(\"viridis\").copy()\n",
    "    cmap_tril.set_under('black')\n",
    "    mask_tril=np.tri(len(feats_cnt), len(feats_cnt), -1, dtype=bool).T\n",
    "    heatmap_pval = sns.heatmap(\n",
    "        df_corr_fdr,\n",
    "        mask=mask_tril,\n",
    "        annot=True,\n",
    "        fmt=\".1f\",\n",
    "        vmin=-np.log10(0.05),\n",
    "        cmap=cmap_tril,\n",
    "        linewidth=0.1,\n",
    "        linecolor='black',\n",
    "        annot_kws={\"size\": 5},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.figure.axes[-1].set_ylabel(r\"$-\\log_{10}(\\mathrm{p-value})$\", size=13)\n",
    "    for spine in ax.figure.axes[-1].spines.values():\n",
    "        spine.set(visible=True, lw=0.25, edgecolor=\"black\")\n",
    "    ax.set_xlabel('', fontsize=16)\n",
    "    ax.set_ylabel('', fontsize=16)\n",
    "    ax.set_title('', fontsize=16)\n",
    "    # ax.set_xticklabels(ax.get_xticklabels(), path_effects=[pe.withStroke(linewidth=0.5, foreground=\"black\")])\n",
    "    # for tick_label in ax.get_xticklabels():\n",
    "        # tick_label.set_color(colors_tissues[tick_label.get_text()])\n",
    "        # ax.set_xticklabels(ax.get_xticklabels(), path_effects=[pe.withStroke(linewidth=0.5, foreground=\"black\")])\n",
    "    # for tick_label in ax.get_yticklabels():\n",
    "        # tick_label.set_color(colors_tissues[tick_label.get_text()])\n",
    "        # ax.set_yticklabels(ax.get_yticklabels(), path_effects=[pe.withStroke(linewidth=0.5, foreground=\"black\")])\n",
    "    plt.savefig(f\"{path}/{fs}/feats_pearsonr.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path}/{fs}/feats_pearsonr.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
