{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "import torch\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.utils.hash import dict_hash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_data = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/060_EpiSImAge/SImAge_repeat\"\n",
    "path_configs = \"D:/Work/bbs/notebooks/immunology/001_pytorch_tabular_SImAge_repeat\"\n",
    "data = pd.read_excel(f\"{path_data}/data.xlsx\", index_col=1)\n",
    "feats = pd.read_excel(f\"{path_data}/feats_con10.xlsx\", index_col=0).index.values.tolist()\n",
    "cv_df = pd.read_excel(f\"{path_data}/cv_ids.xlsx\", index_col=0)\n",
    "cv_df = cv_df.loc[data.index, :]\n",
    "train_only = data.loc[cv_df.index[cv_df['fold_0002'] == 'trn'].values, feats + ['Age']]\n",
    "validation_only = data.loc[cv_df.index[cv_df['fold_0002'] == 'val'].values, feats + ['Age']]\n",
    "train_validation = data.loc[data[\"Dataset\"] == \"Train/Validation\", feats + ['Age']]\n",
    "test = data.loc[data[\"Dataset\"] == \"Test Controls\", feats + ['Age']]\n",
    "cv_indexes = [\n",
    "    (\n",
    "        np.where(train_validation.index.isin(cv_df.index[cv_df[f\"fold_{i:04d}\"] == 'trn']))[0],\n",
    "        np.where(train_validation.index.isin(cv_df.index[cv_df[f\"fold_{i:04d}\"] == 'val']))[0],\n",
    "    ) \n",
    "    for i in range(5)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Models Search Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## GANDALF Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"model_config__gflu_stages\": [5, 10, 15, 20, 25, 30, 35],\n",
    "    \"model_config__gflu_dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__gflu_feature_init_sparsity\": [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [42, 1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/GANDALFConfig.yaml\", GANDALFConfig)\n",
    "print(np.prod([len(p_vals) for p_name, p_vals in search_space.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CategoryEmbeddingModel Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"model_config__layers\": [\"256-128-64\", \"512-256-128\", \"32-16\", \"32-32-16\", \"16-8\", \"32-16-8\", \"128-64\", \"128-128\", \"16-16\"],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [42, 1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/CategoryEmbeddingModelConfig.yaml\", CategoryEmbeddingModelConfig)\n",
    "print(np.prod([len(p_vals) for _, p_vals in search_space.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## TabNetModel Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"model_config__n_d\": [8, 16, 24, 32, 40, 48],\n",
    "    \"model_config__n_a\": [8, 16, 24, 32, 40, 48],\n",
    "    \"model_config__n_steps\": [3, 5, 7],\n",
    "    \"model_config__gamma\": [1.3, 1.4, 1.5, 1.6, 1.7, 1.8],\n",
    "    \"model_config__n_independent\": [1, 2, 3, 4, 5],\n",
    "    \"model_config__n_shared\": [1, 2, 3, 4, 5],\n",
    "    \"model_config__mask_type\": [\"sparsemax\", \"entmax\"],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [42, 1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/TabNetModelConfig.yaml\", TabNetModelConfig)\n",
    "print(np.prod([len(p_vals) for _, p_vals in search_space.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## FTTransformer Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"model_config__num_heads\": [2, 4, 8, 16, 32],\n",
    "    \"model_config__num_attn_blocks\": [4, 6, 8, 10, 12],\n",
    "    \"model_config__attn_dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__add_norm_dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__ff_dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [42, 1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/FTTransformerConfig.yaml\", FTTransformerConfig)\n",
    "print(np.prod([len(p_vals) for _, p_vals in search_space.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DANet Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"model_config__n_layers\": [4, 8, 16, 20, 32],\n",
    "    \"model_config__abstlay_dim_1\": [8, 16, 32, 64],\n",
    "    \"model_config__k\": [3, 4, 5, 6, 7],\n",
    "    \"model_config__dropout_rate\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [42, 1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/DANetConfig.yaml\", DANetConfig)\n",
    "print(np.prod([len(p_vals) for _, p_vals in search_space.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Grid Search and Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "strategy = 'random_search' # 'grid_search'\n",
    "seed = 456456456\n",
    "n_random_trials = 500\n",
    "is_cross_validation = False\n",
    "\n",
    "data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "data_config['continuous_feature_transform'] = 'quantile_normal'\n",
    "data_config['normalize_continuous_features'] = True\n",
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "trainer_config['checkpoints'] = None\n",
    "trainer_config['load_best'] = False\n",
    "trainer_config['auto_lr_find'] = True\n",
    "optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "\n",
    "tuner = TabularModelTuner(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    suppress_lightning_logger=True,\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    if is_cross_validation:\n",
    "        result = tuner.tune(\n",
    "        train=train_validation,\n",
    "        validation=None,\n",
    "        search_space=search_space,\n",
    "        metric=\"mean_absolute_error\",\n",
    "        mode=\"min\",\n",
    "        strategy=strategy,\n",
    "        n_trials=n_random_trials,\n",
    "        cv=cv_indexes,\n",
    "        return_best_model=True,\n",
    "        verbose=False,\n",
    "        progress_bar=True,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    else:\n",
    "        result = tuner.tune(\n",
    "            train=train_only,\n",
    "            validation=validation_only,\n",
    "            search_space=search_space,\n",
    "            metric=\"mean_absolute_error\",\n",
    "            mode=\"min\",\n",
    "            strategy=strategy,\n",
    "            n_trials=n_random_trials,\n",
    "            cv=None,\n",
    "            return_best_model=True,\n",
    "            verbose=False,\n",
    "            progress_bar=False,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "result.trials_df.to_excel(f\"{trainer_config['checkpoints_path']}/trials/{model_config['_model_name']}_{strategy}_{seed}_{optimizer_config['lr_scheduler']}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Sweep Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate models' configs from trials files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_top_trials = 50\n",
    "\n",
    "target_models_types = [\n",
    "    # 'CategoryEmbeddingModel',\n",
    "    'GANDALF',\n",
    "    'TabNetModel',\n",
    "    # 'FTTransformer',\n",
    "    'DANet'\n",
    "]\n",
    "\n",
    "data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "\n",
    "common_params = {\n",
    "    \"task\": \"regression\",\n",
    "}\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\",\n",
    "    activation='ReLU',\n",
    "    dropout=0.1,\n",
    "    use_batch_norm=False,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__\n",
    "\n",
    "model_list = []\n",
    "for model_type in target_models_types:\n",
    "    trials_files = glob(f\"{trainer_config['checkpoints_path']}/trials/{model_type}*.xlsx\")\n",
    "    for trials_file in trials_files:\n",
    "        df_trials = pd.read_excel(trials_file, index_col=0)\n",
    "        df_trials.sort_values(['mean_absolute_error'], ascending=[True], inplace=True)\n",
    "        df_trials = df_trials.head(n_top_trials)\n",
    "        for _, row in df_trials.iterrows():\n",
    "            head_config_tmp = copy.deepcopy(head_config)\n",
    "            head_config_tmp['dropout'] = float(row['model_config.head_config__dropout'])\n",
    "            if model_type == 'CategoryEmbeddingModel':\n",
    "                model_config = read_parse_config(f\"{path_configs}/{model_type}Config.yaml\", CategoryEmbeddingModelConfig)\n",
    "                model_config['layers'] = row['model_config__layers']\n",
    "                model_config['learning_rate'] = row['model_config__learning_rate']\n",
    "                model_config['seed'] = row['model_config__seed']\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(CategoryEmbeddingModelConfig(**model_config))\n",
    "            elif model_type == 'GANDALF':\n",
    "                model_config = read_parse_config(f\"{path_configs}/{model_type}Config.yaml\", GANDALFConfig)\n",
    "                model_config['gflu_stages'] = int(row['model_config__gflu_stages'])\n",
    "                model_config['gflu_feature_init_sparsity'] = float(row['model_config__gflu_feature_init_sparsity'])\n",
    "                model_config['gflu_dropout'] = float(row['model_config__gflu_dropout'])\n",
    "                model_config['learning_rate'] = float(row['model_config__learning_rate'])\n",
    "                model_config['seed'] = int(row['model_config__seed'])\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(GANDALFConfig(**model_config))\n",
    "            elif model_type == 'TabNetModel':\n",
    "                model_config = read_parse_config(f\"{path_configs}/{model_type}Config.yaml\", TabNetModelConfig)\n",
    "                model_config['n_steps'] = row['model_config__n_steps']\n",
    "                model_config['n_shared'] = row['model_config__n_shared']\n",
    "                model_config['n_independent'] = row['model_config__n_independent']\n",
    "                model_config['n_d'] = row['model_config__n_d']\n",
    "                model_config['n_a'] = row['model_config__n_a']\n",
    "                model_config['mask_type'] = row['model_config__mask_type']\n",
    "                model_config['gamma'] = row['model_config__gamma']\n",
    "                model_config['learning_rate'] = row['model_config__learning_rate']\n",
    "                model_config['seed'] = row['model_config__seed']\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(TabNetModelConfig(**model_config))\n",
    "            elif model_type == 'FTTransformer':\n",
    "                model_config = read_parse_config(f\"{path_configs}/{model_type}Config.yaml\", FTTransformerConfig)\n",
    "                model_config['num_heads'] = int(row['model_config__num_heads'])\n",
    "                model_config['num_attn_blocks'] = int(row['model_config__num_attn_blocks'])\n",
    "                model_config['attn_dropout'] = float(row['model_config__attn_dropout'])\n",
    "                model_config['add_norm_dropout'] = float(row['model_config__add_norm_dropout'])\n",
    "                model_config['ff_dropout'] = float(row['model_config__ff_dropout'])\n",
    "                model_config['learning_rate'] = float(row['model_config__learning_rate'])\n",
    "                model_config['seed'] = int(row['model_config__seed'])\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(FTTransformerConfig(**model_config))\n",
    "            elif model_type == 'DANet':\n",
    "                model_config = read_parse_config(f\"{path_configs}/{model_type}Config.yaml\", DANetConfig)\n",
    "                model_config['n_layers'] = int(row['model_config__n_layers'])\n",
    "                model_config['abstlay_dim_1'] = int(row['model_config__abstlay_dim_1'])\n",
    "                model_config['k'] = int(row['model_config__k'])\n",
    "                model_config['dropout_rate'] = float(row['model_config__dropout_rate'])\n",
    "                model_config['learning_rate'] = float(row['model_config__learning_rate'])\n",
    "                model_config['seed'] = int(row['model_config__seed'])\n",
    "                model_config['head_config'] = head_config_tmp\n",
    "                model_list.append(DANetConfig(**model_config))\n",
    "print(len(model_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Perform model sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "seed = 666\n",
    "\n",
    "trainer_config['seed'] = seed\n",
    "trainer_config['checkpoints'] = 'valid_loss'\n",
    "trainer_config['load_best'] = True\n",
    "trainer_config['auto_lr_find'] = True\n",
    "\n",
    "data_config['continuous_feature_transform'] = 'yeo-johnson' #  'box-cox' 'yeo-johnson' 'quantile_normal'\n",
    "data_config['normalize_continuous_features'] = True\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sweep_df, best_model = model_sweep_custom(\n",
    "        task=\"regression\",\n",
    "        # train=train_validation,\n",
    "        train=train_only,\n",
    "        # validation=None,\n",
    "        validation=validation_only,\n",
    "        test=test,\n",
    "        data_config=data_config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        model_list=model_list,\n",
    "        common_model_args=common_params,\n",
    "        metrics=[\"mean_absolute_error\", \"pearson_corrcoef\"],\n",
    "        metrics_params=[{}, {}],\n",
    "        metrics_prob_input=[False, False],\n",
    "        rank_metric=(\"mean_absolute_error\", \"lower_is_better\"),\n",
    "        return_best_model=True,\n",
    "        seed=seed,\n",
    "        progress_bar=False,\n",
    "        verbose=False,\n",
    "        suppress_lightning_logger=True,\n",
    "    )\n",
    "fn_suffix = f\"{seed}_{best_model.config['lr_scheduler']}_{best_model.config['continuous_feature_transform']}\"\n",
    "sweep_df.style.background_gradient(\n",
    "    subset=[\n",
    "        \"train_loss\",\n",
    "        \"validation_loss\",\n",
    "        \"test_loss\",\n",
    "        \"time_taken\",\n",
    "        \"time_taken_per_epoch\"\n",
    "    ], cmap=\"RdYlGn_r\"\n",
    ").to_excel(f\"{trainer_config['checkpoints_path']}/sweep_{fn_suffix}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "sweep_df = pd.read_excel(f\"{trainer_config['checkpoints_path']}/progress.xlsx\", index_col=0)\n",
    "\n",
    "models_ids = [318, 129, 417, 402, 142, 346]\n",
    "\n",
    "for model_id in models_ids:\n",
    "\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=ast.literal_eval(sweep_df.at[model_id, 'params']),\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        verbose=True,\n",
    "        suppress_lightning_logger=False\n",
    "    )\n",
    "    datamodule = tabular_model.prepare_dataloader(\n",
    "        train=train_only,\n",
    "        validation=validation_only,\n",
    "        seed=seed,\n",
    "    )\n",
    "    model = tabular_model.prepare_model(\n",
    "        datamodule\n",
    "    )\n",
    "    tabular_model._prepare_for_training(\n",
    "        model,\n",
    "        datamodule\n",
    "    )\n",
    "    tabular_model.load_weights(sweep_df.at[model_id, 'checkpoint'])\n",
    "    tabular_model.evaluate(test, verbose=False)\n",
    "    tabular_model.save_model(f\"{tabular_model.config['checkpoints_path']}/candidates/{model_id}\")\n",
    "    \n",
    "    loaded_model = TabularModel.load_model(f\"{tabular_model.config['checkpoints_path']}/candidates/{model_id}\")\n",
    "    \n",
    "    df = data.loc[:, ['Age', 'Sex', 'Status']]\n",
    "    df['Group'] = df['Status']\n",
    "    df.loc[train_only.index, 'Group'] = 'Train'\n",
    "    df.loc[validation_only.index, 'Group'] = 'Validation'\n",
    "    df.loc[test.index, 'Group'] = 'Test'\n",
    "    df['Prediction'] = loaded_model.predict(data)\n",
    "    df['Error'] = df['Prediction'] - df['Age']\n",
    "    df.to_csv(f\"{loaded_model.config['checkpoints_path']}/candidates/{model_id}/df.xlsx\")\n",
    "    \n",
    "    colors_groups = {\n",
    "        'Train': 'chartreuse',\n",
    "        'Validation': 'lightskyblue',\n",
    "        'Test': 'dodgerblue',\n",
    "        'ESRD': 'crimson'\n",
    "    }\n",
    "    \n",
    "    df_metrics = pd.DataFrame(\n",
    "        index=list(colors_groups.keys()),\n",
    "        columns=['mean_absolute_error', 'pearson_corrcoef', 'mean_age_acc']\n",
    "    )\n",
    "    for group in colors_groups.keys():\n",
    "        pred = torch.from_numpy(df.loc[df['Group'] == group, 'Prediction'].values)\n",
    "        real = torch.from_numpy(df.loc[df['Group'] == group, 'Age'].values)\n",
    "        df_metrics.at[group, 'mean_absolute_error'] = mean_absolute_error(pred, real).numpy()\n",
    "        df_metrics.at[group, 'pearson_corrcoef'] = pearson_corrcoef(pred, real).numpy()\n",
    "        df_metrics.at[group, 'mean_age_acc'] = np.mean(df.loc[df['Group'] == group, 'Error'].values)\n",
    "    df_metrics.to_excel(f\"{loaded_model.config['checkpoints_path']}/candidates/{model_id}/metrics.xlsx\", index_label=\"Metrics\")\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4))\n",
    "    scatter = sns.scatterplot(\n",
    "        data=df,\n",
    "        x=\"Age\",\n",
    "        y=\"Prediction\",\n",
    "        hue=\"Group\",\n",
    "        palette=colors_groups,\n",
    "        linewidth=0.2,\n",
    "        alpha=0.75,\n",
    "        edgecolor=\"k\",\n",
    "        s=20,\n",
    "        hue_order=list(colors_groups.keys()),\n",
    "        ax=ax\n",
    "    )\n",
    "    bisect = sns.lineplot(\n",
    "        x=[0, 120],\n",
    "        y=[0, 120],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=1.0,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f\"{sweep_df.at[model_id, 'model']} ({sweep_df.at[model_id, '# Params']} params, {sweep_df.at[model_id, 'epochs']} epochs)\")\n",
    "    ax.set_xlim(0, 120)\n",
    "    ax.set_ylim(0, 120)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    fig.savefig(f\"{loaded_model.config['checkpoints_path']}/candidates/{model_id}/scatter.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{loaded_model.config['checkpoints_path']}/candidates/{model_id}/scatter.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    df_fig = df.loc[:, ['Error', 'Group']]\n",
    "    groups_rename = {\n",
    "        group: f\"{group}\" + \"\\n\" +\n",
    "               fr\"MAE: {df_metrics.at[group, 'mean_absolute_error']:0.2f}\" + \"\\n\"\n",
    "               fr\"Pearson $\\rho$: {df_metrics.at[group, 'pearson_corrcoef']:0.2f}\" + \"\\n\" +\n",
    "               fr\"$\\langle$Error$\\rangle$: {df_metrics.at[group, 'mean_age_acc']:0.2f}\" \n",
    "        for group in colors_groups\n",
    "    }\n",
    "    colors_groups_violin = {groups_rename[group]: colors_groups[group] for group in colors_groups}\n",
    "    df_fig['Group'].replace(groups_rename, inplace=True)\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    violin = sns.violinplot(\n",
    "        data=df_fig,\n",
    "        x='Group',\n",
    "        y='Error',\n",
    "        palette=colors_groups_violin,\n",
    "        scale='width',\n",
    "        order=list(colors_groups_violin.keys()),\n",
    "        saturation=0.75,\n",
    "        legend=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('')\n",
    "    fig.savefig(f\"{loaded_model.config['checkpoints_path']}/candidates/{model_id}/violin.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{loaded_model.config['checkpoints_path']}/candidates/{model_id}/violin.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Simple TabularModel training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "trainer_config['checkpoints'] = 'valid_loss'\n",
    "trainer_config['load_best'] = True\n",
    "trainer_config['auto_lr_find'] = True\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=f\"{path_configs}/DataConfig.yaml\",\n",
    "    model_config=f\"{path_configs}/CategoryEmbeddingModelConfig.yaml\",\n",
    "    optimizer_config=f\"{path_configs}/OptimizerConfig.yaml\",\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=True,\n",
    "    suppress_lightning_logger=False\n",
    ")\n",
    "\n",
    "tabular_model.fit(\n",
    "    train=train_only,\n",
    "    validation=validation_only,\n",
    "    # target_transform=[np.log, np.exp],\n",
    "    # callbacks=[DeviceStatsMonitor()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Play with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabular_model.predict(test, progress_bar='rich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabular_model.evaluate(test, verbose=True, ckpt_path=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabular_model.config['checkpoints_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tabular_model.trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabular_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabular_model.save_model(tabular_model.config['checkpoints_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabular_model.save_config(tabular_model.config['checkpoints_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabular_model = TabularModel.load_model(tabular_model.config['checkpoints_path'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
