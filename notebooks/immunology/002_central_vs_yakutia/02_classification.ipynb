{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Debugging autoreload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "import torch\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.utils.hash import dict_hash\n",
    "from pytorch_tabular.utils import get_balanced_sampler\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path_data = \"D:/YandexDisk/Work/bbd/immunology/002_central_vs_yakutia/classification\"\n",
    "path_configs = \"D:/Work/bbs/notebooks/immunology/002_central_vs_yakutia/pt_configs\"\n",
    "data = pd.read_excel(f\"{path_data}/data.xlsx\", index_col=0)\n",
    "feats = pd.read_excel(f\"{path_data}/feats.xlsx\", index_col=0).index.values.tolist()\n",
    "\n",
    "test_split_id = 0\n",
    "\n",
    "val_n_splits = 4\n",
    "val_random_state = 1337\n",
    "val_fold_id = 0\n",
    "\n",
    "for fold_id in range(val_n_splits):\n",
    "    data[f\"Fold_{fold_id}\"] = data[f\"Split_{test_split_id}\"]\n",
    "\n",
    "stratify_cat_parts = {\n",
    "    'Central': data.index[(data['Region'] == 'Central') & (data[f\"Split_{test_split_id}\"] == 'trn_val')].values,\n",
    "    'Yakutia': data.index[(data['Region'] == 'Yakutia') & (data[f\"Split_{test_split_id}\"] == 'trn_val')].values,\n",
    "}\n",
    "for part, ids in stratify_cat_parts.items():\n",
    "    print(f\"{part}: {len(ids)}\")\n",
    "    con = data.loc[ids, 'Age'].values\n",
    "    ptp = np.ptp(con)\n",
    "    num_bins = 5\n",
    "    bins = np.linspace(np.min(con) - 0.1 * ptp, np.max(con) + 0.1 * ptp, num_bins + 1)\n",
    "    binned = np.digitize(con, bins) - 1\n",
    "    unique, counts = np.unique(binned, return_counts=True)\n",
    "    occ = dict(zip(unique, counts))\n",
    "    k_fold = RepeatedStratifiedKFold(\n",
    "        n_splits=val_n_splits,\n",
    "        n_repeats=1,\n",
    "        random_state=val_random_state\n",
    "    )\n",
    "    splits = k_fold.split(X=ids, y=binned, groups=binned)\n",
    "    \n",
    "    for fold_id, (ids_trn, ids_val) in enumerate(splits):\n",
    "        data.loc[ids[ids_trn], f\"Fold_{fold_id}\"] = \"trn\"\n",
    "        data.loc[ids[ids_val], f\"Fold_{fold_id}\"] = \"val\"\n",
    "        \n",
    "test = data.loc[data[f\"Split_{test_split_id}\"] == \"tst\", feats + ['Region']]\n",
    "train_validation = data.loc[data[f\"Split_{test_split_id}\"] == \"trn_val\", feats + ['Region'] + [f\"Fold_{i}\" for i in range(val_n_splits)]]\n",
    "train_only = data.loc[data[f\"Fold_{val_fold_id}\"] == \"trn\", feats + ['Region']]\n",
    "validation_only = data.loc[data[f\"Fold_{val_fold_id}\"] == \"val\", feats + ['Region']]\n",
    "cv_indexes = [\n",
    "    (\n",
    "        np.where(train_validation.index.isin(train_validation.index[train_validation[f\"Fold_{i}\"] == 'trn']))[0],\n",
    "        np.where(train_validation.index.isin(train_validation.index[train_validation[f\"Fold_{i}\"] == 'val']))[0],\n",
    "    )\n",
    "    for i in range(val_n_splits)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare balanced sampler"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sampler_balanced = get_balanced_sampler(train_only['Region'].values.ravel())",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Models Search Spaces"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CategoryEmbeddingModel Search Space"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    \"model_config__layers\": [\"256-128-64\", \"512-256-128\", \"32-16\", \"32-32-16\", \"16-8\", \"32-16-8\", \"128-64\", \"128-128\", \"16-16\"],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [42, 1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/models/CategoryEmbeddingModelConfig.yaml\", CategoryEmbeddingModelConfig)\n",
    "grid_size = np.prod([len(p_vals) for _, p_vals in search_space.items()])\n",
    "print(grid_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## GANDALF Search Space"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_space = {\n",
    "    \"model_config__gflu_stages\": [5, 10, 15, 20, 25, 30, 35],\n",
    "    \"model_config__gflu_dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__gflu_feature_init_sparsity\": [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    \"model_config.head_config__dropout\": [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    \"model_config__learning_rate\": [0.001],\n",
    "    \"model_config__seed\": [1337, 666],\n",
    "}\n",
    "model_config = read_parse_config(f\"{path_configs}/models/GANDALFConfig.yaml\", GANDALFConfig)\n",
    "grid_size = np.prod([len(p_vals) for _, p_vals in search_space.items()])\n",
    "print(grid_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Grid Search and Random Search"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "strategy = 'random_search' # 'grid_search'\n",
    "seed = 1337\n",
    "n_random_trials = 200\n",
    "is_cross_validation = True\n",
    "\n",
    "if grid_size < n_random_trials and strategy == 'random_search':\n",
    "    strategy = 'grid_search'\n",
    "\n",
    "data_config = read_parse_config(f\"{path_configs}/DataConfig.yaml\", DataConfig)\n",
    "data_config['continuous_feature_transform'] = 'yeo-johnson'\n",
    "data_config['normalize_continuous_features'] = True\n",
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "trainer_config['checkpoints'] = None\n",
    "trainer_config['load_best'] = False\n",
    "trainer_config['auto_lr_find'] = True\n",
    "optimizer_config = read_parse_config(f\"{path_configs}/OptimizerConfig.yaml\", OptimizerConfig)\n",
    "\n",
    "tuner = TabularModelTuner(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    suppress_lightning_logger=True,\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    if is_cross_validation:\n",
    "        result = tuner.tune(\n",
    "            train=train_validation,\n",
    "            validation=None,\n",
    "            search_space=search_space,\n",
    "            metric=\"accuracy\",\n",
    "            mode=\"max\",\n",
    "            strategy=strategy,\n",
    "            n_trials=n_random_trials,\n",
    "            cv=cv_indexes,\n",
    "            return_best_model=True,\n",
    "            verbose=False,\n",
    "            progress_bar=False,\n",
    "            random_state=seed,\n",
    "            train_sampler=sampler_balanced\n",
    "        )\n",
    "    else:\n",
    "        result = tuner.tune(\n",
    "            train=train_only,\n",
    "            validation=validation_only,\n",
    "            search_space=search_space,\n",
    "            metric=\"accuracy\",\n",
    "            mode=\"max\",\n",
    "            strategy=strategy,\n",
    "            n_trials=n_random_trials,\n",
    "            cv=None,\n",
    "            return_best_model=True,\n",
    "            verbose=False,\n",
    "            progress_bar=False,\n",
    "            random_state=seed,\n",
    "            train_sampler=sampler_balanced\n",
    "        )\n",
    "\n",
    "result.trials_df.to_excel(f\"{trainer_config['checkpoints_path']}/trials/{model_config['_model_name']}_{strategy}_{seed}_{optimizer_config['lr_scheduler']}.xlsx\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple TabularModel training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_config = read_parse_config(f\"{path_configs}/TrainerConfig.yaml\", TrainerConfig)\n",
    "trainer_config['checkpoints'] = 'valid_loss'\n",
    "trainer_config['load_best'] = True\n",
    "trainer_config['auto_lr_find'] = True\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=f\"{path_configs}/DataConfig.yaml\",\n",
    "    model_config=f\"{path_configs}/models/CategoryEmbeddingModelConfig.yaml\",\n",
    "    optimizer_config=f\"{path_configs}/OptimizerConfig.yaml\",\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=True,\n",
    "    suppress_lightning_logger=False\n",
    ")\n",
    "\n",
    "tabular_model.fit(\n",
    "    train=train_only,\n",
    "    validation=validation_only,\n",
    "    # target_transform=[np.log, np.exp],\n",
    "    # callbacks=[DeviceStatsMonitor()],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Play with trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.predict(test, progress_bar='rich')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.evaluate(test, verbose=True, ckpt_path=\"best\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.config['checkpoints_path']"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(tabular_model.trainer.checkpoint_callback.best_model_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.save_model(tabular_model.config['checkpoints_path'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model.save_config(tabular_model.config['checkpoints_path'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tabular_model = TabularModel.load_model(tabular_model.config['checkpoints_path'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
