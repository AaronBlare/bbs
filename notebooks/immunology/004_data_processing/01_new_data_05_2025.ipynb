{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T14:29:22.801727Z",
     "start_time": "2024-07-01T14:29:18.695223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from plotly.subplots import make_subplots\n",
    "from pytorch_tabular import TabularModel\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "from src.utils.hash import dict_hash\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import distinctipy\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.colors as mcolors\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu, variation, levene\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.plots import bar\n",
    "from plottable.cmap import normed_cmap, centered_cmap\n",
    "import optuna\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.cm\n",
    "import matplotlib as mpl\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import re\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from itertools import chain\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pyaging as pya\n",
    "import matplotlib.lines as mlines\n",
    "from src.models.simage.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "import statsmodels.formula.api as smf\n",
    "from itertools import chain\n",
    "from pingouin import ancova\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import upsetplot\n",
    "\n",
    "\n",
    "def make_rgb_transparent(rgb, bg_rgb, alpha):\n",
    "    return [alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, bg_rgb)]\n",
    "\n",
    "\n",
    "def form_bar(base):\n",
    "    def formatter(x):\n",
    "        return f'{str(int(round(x * base)))}/{base}'\n",
    "    return formatter\n",
    "\n",
    "\n",
    "def get_sections(sets):\n",
    "    \"\"\"\n",
    "    Given a list of sets, return a new list of sets with all the possible\n",
    "    mutually exclusive overlapping combinations of those sets.  Another way\n",
    "    to think of this is the mutually exclusive sections of a venn diagram\n",
    "    of the sets.  If the original list has N sets, the returned list will\n",
    "    have (2**N)-1 sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sets : list of set\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    combinations : list of tuple\n",
    "        tag : str\n",
    "            Binary string representing which sets are included / excluded in\n",
    "            the combination.\n",
    "        set : set\n",
    "            The set formed by the overlapping input sets.\n",
    "    \"\"\"\n",
    "    num_combinations = 2 ** len(sets)\n",
    "    bit_flags = [2 ** n for n in range(len(sets))]\n",
    "    flags_zip_sets = [z for z in zip(bit_flags, sets)]\n",
    "\n",
    "    combo_sets = {}\n",
    "    for bits in range(num_combinations - 1, 0, -1):\n",
    "        include_sets = [s for flag, s in flags_zip_sets if bits & flag]\n",
    "        exclude_sets = [s for flag, s in flags_zip_sets if not bits & flag]\n",
    "        combo = set.intersection(*include_sets)\n",
    "        combo = set.difference(combo, *exclude_sets)\n",
    "        tag = ''.join([str(int((bits & flag) > 0)) for flag in bit_flags])\n",
    "        combo_sets[tag] = combo\n",
    "    return combo_sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all aux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"E:/YandexDisk/Work/bbd/immunology/004_data_processing\"\n",
    "path_unn = f\"E:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "\n",
    "feats_imm = pd.read_excel(f\"{path_unn}/data/immuno/feats_con.xlsx\", index_col=0).index.values\n",
    "feats_imm_fimmu = pd.read_excel(f\"{path_unn}/data/immuno/models/SImAge/feats_con_top10.xlsx\", index_col=0).index.values\n",
    "feats_imm_slctd = pd.read_excel(f\"{path_unn}/special/059_imm_data_selection/feats_selected.xlsx\", index_col=0).index.values\n",
    "feats_imm_genes = pd.read_excel(f\"{path_unn}/data/immuno/immuno_markers_genes.xlsx\", index_col=0)\n",
    "feats_imm_rename = dict(zip(feats_imm_genes.index, feats_imm_genes['gene']))\n",
    "\n",
    "imm_old = pd.read_excel(f\"{path}/data_GSEUNN_fmba.xlsx\", index_col=0)\n",
    "imm_old.index = imm_old.index.astype(str)\n",
    "print(f\"imm_old index unique: {imm_old.index.is_unique}\")\n",
    "imm_old_w_nans = pd.read_excel(f\"{path}/data_GSEUNN_fmba_with_nans.xlsx\", index_col=0)\n",
    "imm_old_w_nans.index = imm_old_w_nans.index.astype(str)\n",
    "print(f\"imm_old_w_nans index unique: {imm_old_w_nans.index.is_unique}\")\n",
    "imm_old_selected = pd.read_excel(f\"{path_unn}/special/059_imm_data_selection/df_imm.xlsx\", index_col=0)\n",
    "imm_old_selected.index = imm_old_selected.index.astype(str)\n",
    "print(f\"imm_old_selected index unique: {imm_old_selected.index.is_unique}\")\n",
    "\n",
    "ids_groups = {\n",
    "    'Old Central': imm_old_selected.index[imm_old_selected['Region'] == 'Central'].values,\n",
    "    'Old Yakutia': imm_old_selected.index[imm_old_selected['Region'] == 'Yakutia'].values,\n",
    "    'Old Mirny': imm_old.index[imm_old['Region'] == 'Mirny'].values,\n",
    "    'Old FMBA': imm_old.index[imm_old['Region'].isna()].values,\n",
    "}\n",
    "imm_old.loc[ids_groups['Old FMBA'], 'Sex'] = 'M'\n",
    "imm_old.loc[ids_groups['Old FMBA'], 'Subject ID'] = imm_old.index[ids_groups['Old FMBA']].values\n",
    "imm_old.insert(2, 'Group', None)\n",
    "imm_old.insert(2, 'Group detailed', None)\n",
    "for group_name, ids_group in ids_groups.items():\n",
    "    imm_old.loc[ids_group, 'Group'] = group_name\n",
    "    imm_old.loc[ids_group, 'Group detailed'] = group_name\n",
    "\n",
    "df_samples_mirny_1 = pd.read_excel(f\"E:/YandexDisk/Work/bbd/mirny/select_20_samples/selected.xlsx\", index_col=0)\n",
    "df_samples_mirny_1.index = df_samples_mirny_1.index.astype(str)\n",
    "df_samples_mirny_1['Group'] = 'New 2025'\n",
    "df_samples_mirny_1['Group detailed'] = 'New 2025 Mirny'\n",
    "print(f\"Mirny subset 1 index unique: {df_samples_mirny_1.index.is_unique}\")\n",
    "df_samples_mirny_2 = pd.read_excel(f\"E:/YandexDisk/Work/bbd/mirny/select_20_samples/selected_new_20.xlsx\", index_col=0)\n",
    "df_samples_mirny_2.index = df_samples_mirny_2.index.astype(str)\n",
    "df_samples_mirny_2['Group'] = 'New 2025'\n",
    "df_samples_mirny_2['Group detailed'] = 'New 2025 Mirny'\n",
    "print(f\"Mirny subset 2 index unique: {df_samples_mirny_2.index.is_unique}\")\n",
    "\n",
    "df_samples_mriya_epi = pd.read_excel(f\"E:/YandexDisk/Work/bbd/mriya/select_samples/Эпи.xlsx\", index_col=0)\n",
    "df_samples_mriya_epi.index = df_samples_mriya_epi.index.astype(str)\n",
    "df_samples_mriya_epi['Group'] = 'New 2025'\n",
    "df_samples_mriya_epi['Group detailed'] = 'New 2025 UNN'\n",
    "print(f\"Mriya ЭПИ index unique: {df_samples_mriya_epi.index.is_unique}\")\n",
    "df_samples_mriya_80 = pd.read_excel(f\"E:/YandexDisk/Work/bbd/mriya/select_samples/80.xlsx\", index_col=0)\n",
    "df_samples_mriya_80.index = df_samples_mriya_80.index.astype(str)\n",
    "df_samples_mriya_80['Group'] = 'New 2025'\n",
    "df_samples_mriya_80['Group detailed'] = 'New 2025 UNN'\n",
    "print(f\"Mriya 80 index unique: {df_samples_mriya_80.index.is_unique}\")\n",
    "\n",
    "df_samples_fmba_20 = pd.read_excel(f\"E:/YandexDisk/Work/bbd/fmba/04_select_samples_20/selected.xlsx\", index_col=0)\n",
    "df_samples_fmba_20.index = df_samples_fmba_20.index.astype(str)\n",
    "df_samples_fmba_20['Sex'] = 'M'\n",
    "df_samples_fmba_20['Group'] = 'New 2025'\n",
    "df_samples_fmba_20['Group detailed'] = 'New 2025 FMBA'\n",
    "print(f\"FMBA 20 index unique: {df_samples_fmba_20.index.is_unique}\")\n",
    "\n",
    "df_samples_fmba_epi = pd.read_excel(f\"E:/YandexDisk/Work/bbd/fmba/dnam/processed/pheno.xlsx\", index_col=0)\n",
    "df_samples_fmba_epi.index = df_samples_fmba_epi.index.astype(str)\n",
    "df_samples_fmba_epi['Group'] = 'New 2025'\n",
    "df_samples_fmba_epi['Group detailed'] = 'New 2025 FMBA'\n",
    "print(f\"FMBA Epi index unique: {df_samples_fmba_epi.index.is_unique}\")\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"Mirny subset 1 (20): {len(imm_old.index.intersection(df_samples_mirny_1.index).to_list())}\")\n",
    "print(f\"Mirny subset 2 (20): {len(imm_old.index.intersection(df_samples_mirny_2.index).to_list())}\")\n",
    "print(f\"Mirny subset 1 and 2 intersection: {len(df_samples_mirny_1.index.intersection(df_samples_mirny_2.index).to_list())}\")\n",
    "print(f\"FMBA subset (20 or 13?): {len(imm_old.index.intersection(df_samples_fmba_20.index).to_list())}\")\n",
    "print(f\"Missed FMBA samples: {df_samples_fmba_20.index.difference(imm_old.index).to_list()}\")\n",
    "print(f\"Mriya ЭПИ intersection with old UNN data: {len(imm_old.index.intersection(df_samples_mriya_epi.index).to_list())}\")\n",
    "print(f\"Mriya 80 intersection with old UNN data: {len(imm_old.index.intersection(df_samples_mriya_80.index).to_list())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process duplicates in immuno data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_new = pd.read_excel(f\"{path_unn}/data/immuno/files/processed/07-May-2025/NN-18.04.2025.xlsx\", index_col=0)\n",
    "imm_new.index = imm_new.index.astype(str)\n",
    "print(f\"imm_new index unique: {imm_new.index.is_unique}\")\n",
    "print(f\"num duplicated indexes: {len(imm_new.index[imm_new.index.duplicated()].unique())}\")\n",
    "imm_new.insert(0, 'Subject ID', imm_new.index.values)\n",
    "imm_new.insert(1, 'Has technical duplicates?', False)\n",
    "imm_new.insert(2, 'Age', None)\n",
    "imm_new.insert(3, 'Sex', None)\n",
    "imm_new.insert(4, 'Group', None)\n",
    "imm_new.insert(5, 'Group detailed', None)\n",
    "\n",
    "# Fill Age and Sex\n",
    "imm_new.fillna(df_samples_mirny_1[['Age', 'Sex', 'Group', 'Group detailed']], inplace=True)\n",
    "imm_new.fillna(df_samples_mirny_2[['Age', 'Sex', 'Group', 'Group detailed']], inplace=True)\n",
    "imm_new.fillna(df_samples_mriya_epi[['Age', 'Sex', 'Group', 'Group detailed']], inplace=True)\n",
    "imm_new.fillna(df_samples_mriya_80[['Age', 'Sex', 'Group', 'Group detailed']], inplace=True)\n",
    "imm_new.fillna(df_samples_fmba_20[['Age', 'Sex', 'Group', 'Group detailed']], inplace=True)\n",
    "imm_new.fillna(df_samples_fmba_epi[['Age', 'Sex', 'Group', 'Group detailed']], inplace=True)\n",
    "\n",
    "# Process duplicates\n",
    "imm_new.loc[imm_new.index[imm_new.index.duplicated()], 'Has technical duplicates?'] = True\n",
    "imm_new.index = imm_new.index.where(\n",
    "    ~imm_new.index.duplicated(keep=False),  # Маска для уникальных элементов\n",
    "    imm_new.index + '_technical_duplicate_' + imm_new.groupby(imm_new.index).cumcount().astype(str)  # Суффиксы для дубликатов\n",
    ")\n",
    "imm_new.index = imm_new.index.str.replace('_technical_duplicate_0', '')\n",
    "print(f\"imm_new index unique: {imm_new.index.is_unique}\")\n",
    "imm_new.to_excel(f\"{path_unn}/data/immuno/files/processed/07-May-2025/NN-18.04.2025_processed_duplicates.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load duplicates-processed immuno data and impute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_new = pd.read_excel(f\"{path_unn}/data/immuno/files/processed/07-May-2025/NN-18.04.2025_processed_duplicates.xlsx\", index_col=0)\n",
    "imm_new.index = imm_new.index.astype(str)\n",
    "imm_new.rename(columns=feats_imm_rename, inplace=True)\n",
    "print(f\"imm_new index unique: {imm_new.index.is_unique}\")\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"Mirny subset 1 (20): {len(imm_new.index.intersection(df_samples_mirny_1.index).to_list())}\")\n",
    "print(f\"Mirny subset 2 (20): {len(imm_new.index.intersection(df_samples_mirny_2.index).to_list())}\")\n",
    "print(f\"FMBA subset (20 or 13?): {len(imm_new.index.intersection(df_samples_fmba_20.index).to_list())}\")\n",
    "print(f\"Missed FMBA samples: {df_samples_fmba_20.index.difference(imm_new.index).to_list()}\")\n",
    "print(f\"Mriya ЭПИ (96): {len(imm_new.index.intersection(df_samples_mriya_epi.index).to_list())}\")\n",
    "print(f\"Missed Mriya ЭПИ (96): {df_samples_mriya_epi.index.difference(imm_new.index).to_list()}\")\n",
    "print(f\"Mriya 80 (80): {len(imm_new.index.intersection(df_samples_mriya_80.index).to_list())}\")\n",
    "print(f\"Missed Mriya ЭПИ (96): {df_samples_mriya_80.index.difference(imm_new.index).to_list()}\")\n",
    "\n",
    "# Data with NaNs\n",
    "imm_w_nans = imm_new.copy()\n",
    "imm_w_nans.replace(r'^([\\<].*)$', 'NaN', inplace=True, regex=True)\n",
    "imm_w_nans.replace(r'^([\\>].*)$', 'NaN', inplace=True, regex=True)\n",
    "imm_w_nans[feats_imm] = imm_w_nans[feats_imm].apply(pd.to_numeric, errors='coerce')\n",
    "imm_w_nans[feats_imm].to_excel(f\"{path}/data_052025_with_nans.xlsx\")\n",
    "\n",
    "# Impute max thresholds\n",
    "imm_max_thld_nans = imm_new.loc[:, feats_imm].copy()\n",
    "imm_max_thld_nans.replace(r'^([\\>].*)$', None, inplace=True, regex=True)\n",
    "imm_max_thld_nans = imm_max_thld_nans.stack(dropna=False)\n",
    "max_thld_nans = [list(x) for x in imm_max_thld_nans.index[imm_max_thld_nans.isna()]]\n",
    "print(f'\\nNumber of max_thld_nans: {len(max_thld_nans)}')\n",
    "imm_max_thld_imp = imm_new.loc[:, feats_imm].copy()\n",
    "imm_max_thld_imp.replace(r'^([\\<].*)$', 'NaN', inplace=True, regex=True)\n",
    "imm_max_thld_imp.replace(r'^([\\>].*)$', 'NaN', inplace=True, regex=True)\n",
    "imm_max_thld_imp = imm_max_thld_imp.apply(pd.to_numeric, errors='coerce')\n",
    "n_neighbors = 3\n",
    "X = imm_max_thld_imp.loc[:, feats_imm].values\n",
    "imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "X_imptd = imputer.fit_transform(X)\n",
    "imm_max_thld_imp.loc[:, feats_imm] = X_imptd\n",
    "\n",
    "# Fill with imputed max thresholds\n",
    "imm_new[feats_imm].replace(r'^([\\<].*)$', 'NaN', inplace=True, regex=True)\n",
    "imm_new[feats_imm].replace(r'^([\\>].*)$', 'NaN', inplace=True, regex=True)\n",
    "imm_new[feats_imm] = imm_new[feats_imm].apply(pd.to_numeric, errors='coerce')\n",
    "print(f'Missing before max thresholds imputation: {imm_new[feats_imm].isna().sum().sum()}')\n",
    "for max_imp_nan in max_thld_nans:\n",
    "    imm_new.at[max_imp_nan[0], max_imp_nan[1]] = imm_max_thld_imp.at[max_imp_nan[0], max_imp_nan[1]]\n",
    "print(f'Missing after max thresholds imputation: {imm_new[feats_imm].isna().sum().sum()}')\n",
    "# Impute min thresholds and replace imputed values with the closest threshold values in Central\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "ids_imp_trn = ids_groups['Old Central']\n",
    "ids_imp_tst = imm_new.index.values\n",
    "df_imp = pd.concat([\n",
    "    imm_old.loc[ids_imp_trn, feats_imm],\n",
    "    imm_new.loc[:, feats_imm]\n",
    "])\n",
    "X = df_imp.loc[:, feats_imm].values\n",
    "imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "X_imptd = imputer.fit_transform(X)\n",
    "df_imp.loc[:, feats_imm] = X_imptd\n",
    "for feat in feats_imm:\n",
    "    srs_feat_base = imm_old_w_nans.loc[ids_imp_trn, feat].isna()\n",
    "    ids_feat_base = srs_feat_base.index[srs_feat_base == True].values\n",
    "    if len(ids_feat_base) > 0:\n",
    "        feat_base_vals = imm_old.loc[ids_feat_base, feat].unique()\n",
    "        srs_feat_trgt = imm_new.loc[ids_imp_tst, feat].isna()\n",
    "        ids_feat_trgt = srs_feat_trgt.index[srs_feat_trgt == True].values\n",
    "        for id_trgt in ids_feat_trgt:\n",
    "            df_imp.at[id_trgt, feat] = find_nearest(feat_base_vals, df_imp.at[id_trgt, feat])\n",
    "imm_new.loc[ids_imp_tst, feats_imm] = df_imp.loc[ids_imp_tst, feats_imm]\n",
    "imm_new.to_excel(f\"{path}/data_052025.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all data, сalculate SImAge, calculate logs, save all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"imm_new index unique: {imm_new.index.is_unique}\")\n",
    "print(f\"imm_old index unique: {imm_old.index.is_unique}\")\n",
    "\n",
    "ids_rep_mes = imm_new.index.intersection(imm_old.index).values\n",
    "print(f\"ids_rep_mes before index correction: {len(ids_rep_mes)}\")\n",
    "\n",
    "imm_new.insert(0, '2025 Repeated Measures?', False)\n",
    "imm_new.insert(1, '2025 Repeated Measures Time', None)\n",
    "imm_new.loc[ids_rep_mes, '2025 Repeated Measures?'] = True\n",
    "imm_new.loc[ids_rep_mes, '2025 Repeated Measures Time'] = 1\n",
    "imm_old.insert(0, '2025 Repeated Measures?', False)\n",
    "imm_old.insert(1, '2025 Repeated Measures Time', None)\n",
    "imm_old.loc[ids_rep_mes, '2025 Repeated Measures?'] = True\n",
    "imm_old.loc[ids_rep_mes, '2025 Repeated Measures Time'] = 0\n",
    "\n",
    "imm_w_nans = imm_w_nans.loc[imm_new.index, :]\n",
    "\n",
    "imm_new['new_index'] = imm_new.index.values\n",
    "imm_new.loc[ids_rep_mes, 'new_index'] += '_repeated_measure_1'\n",
    "imm_new.set_index('new_index', inplace=True)\n",
    "\n",
    "imm_w_nans.set_index(imm_new.index.values, inplace=True)\n",
    "\n",
    "ids_rep_mes = imm_new.index.intersection(imm_old.index)\n",
    "print(f\"ids_rep_mes after index correction: {len(ids_rep_mes)}\")\n",
    "\n",
    "imm_all = pd.concat([imm_old, imm_new])\n",
    "imm_all_with_nans = pd.concat([imm_old_w_nans, imm_w_nans])\n",
    "\n",
    "path_simage = f\"E:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/data/immuno/models/SImAge/best_fold_0002.ckpt\"\n",
    "model_simage = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=path_simage)\n",
    "model_simage.eval()\n",
    "model_simage.freeze()\n",
    "model_simage.to('cpu')\n",
    "imm_all['SImAge'] = model_simage(torch.from_numpy(imm_all.loc[:, feats_imm_fimmu].values)).cpu().detach().numpy().ravel()\n",
    "imm_all['SImAge acceleration'] = imm_all['SImAge'] - imm_all['Age']\n",
    "imm_all['|SImAge acceleration|'] = imm_all['SImAge acceleration'].abs()\n",
    "\n",
    "for f in feats_imm:\n",
    "    imm_all[f\"log({f})\"] = np.log(imm_all[f\"{f}\"])\n",
    "\n",
    "imm_all.to_excel(f\"{path}/data_GSEUNN_fmba_052025.xlsx\")\n",
    "imm_all_with_nans[feats_imm].to_excel(f\"{path}/data_GSEUNN_fmba_052025_with_nans.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"E:/YandexDisk/Work/bbd/immunology/004_data_processing\"\n",
    "path_unn = f\"E:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "\n",
    "imm = pd.read_excel(f\"{path}/data_GSEUNN_fmba_052025.xlsx\", index_col=0)\n",
    "imm.index = imm.index.astype(str)\n",
    "print(f\"Is index unique: {imm.index.is_unique}\")\n",
    "\n",
    "imm_w_nans = pd.read_excel(f\"{path}/data_GSEUNN_fmba_052025_with_nans.xlsx\", index_col=0)\n",
    "imm_w_nans.index = imm_w_nans.index.astype(str)\n",
    "print(f\"Is index unique: {imm_w_nans.index.is_unique}\")\n",
    "\n",
    "feats_imm = pd.read_excel(f\"{path_unn}/data/immuno/feats_con.xlsx\", index_col=0).index.values\n",
    "feats_imm_fimmu = pd.read_excel(f\"{path_unn}/data/immuno/models/SImAge/feats_con_top10.xlsx\", index_col=0).index.values\n",
    "feats_imm_slctd = pd.read_excel(f\"{path_unn}/special/059_imm_data_selection/feats_selected.xlsx\", index_col=0).index.values\n",
    "feats_imm_genes = pd.read_excel(f\"{path_unn}/data/immuno/immuno_markers_genes.xlsx\", index_col=0)\n",
    "feats_imm_rename = dict(zip(feats_imm_genes.index, feats_imm_genes['gene']))\n",
    "\n",
    "feats_colors_raw = distinctipy.get_colors(len(feats_imm), [mcolors.hex2color(mcolors.CSS4_COLORS['black']), mcolors.hex2color(mcolors.CSS4_COLORS['white'])], rng=1899, pastel_factor=0.0)\n",
    "feats_palette = {x: feats_colors_raw[x_id] for x_id, x in enumerate(feats_imm)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/01_new_data_05_2025/nans\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "groups = ['New 2025', 'Old Central', 'Old Yakutia', 'Old Mirny', 'Old FMBA']\n",
    "\n",
    "ids_groups = {x: imm.index[imm['Group'] == x].values for x in groups}\n",
    "\n",
    "colors_groups = {\n",
    "    'Old Central': 'gold',\n",
    "    'Old Yakutia': 'lightslategray',\n",
    "    'Old Mirny': 'crimson',\n",
    "    'Old FMBA': 'dodgerblue',\n",
    "    'New 2025': 'fuchsia'\n",
    "}\n",
    "\n",
    "n_cols = 3\n",
    "n_rows = 2\n",
    "fig_width = 23\n",
    "fig_height = 9\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig_bar, axs_bar = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height), gridspec_kw={}, sharey=False, layout=\"constrained\")\n",
    "fig_hist, axs_hist = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height), gridspec_kw={}, sharex=False, layout=\"constrained\")\n",
    "\n",
    "dfs_nan_feats = {}\n",
    "df_nan_feats_by_group = pd.DataFrame(index=groups)\n",
    "for group_id, group in enumerate(groups):\n",
    "    row_id, col_id = divmod(group_id, n_cols)\n",
    "    \n",
    "    df_nan_feats = imm_w_nans.loc[ids_groups[group], feats_imm].isna().sum(axis=0).to_frame(name=\"Number of NaNs\")\n",
    "    df_nan_feats[\"% of NaNs\"] = df_nan_feats[\"Number of NaNs\"] / len(ids_groups[group]) * 100\n",
    "    df_nan_feats[\"Number of not-NaNs\"] = imm_w_nans.loc[ids_groups[group], feats_imm].notna().sum(axis=0)\n",
    "    df_nan_feats.sort_values([\"% of NaNs\"], ascending=[False], inplace=True)\n",
    "    dfs_nan_feats[group] = df_nan_feats\n",
    "    df_nan_feats_by_group.at[group, \"% of NaNs\"] = df_nan_feats[\"Number of NaNs\"].sum(axis=0) / imm_w_nans.loc[ids_groups[group], feats_imm].size * 100\n",
    "    \n",
    "    barplot = sns.barplot(\n",
    "        data=df_nan_feats,\n",
    "        x=df_nan_feats.index,\n",
    "        y=f\"% of NaNs\",\n",
    "        edgecolor='black',\n",
    "        color=colors_groups[group],\n",
    "        dodge=False,\n",
    "        ax=axs_bar[row_id, col_id],\n",
    "    )\n",
    "    axs_bar[row_id, col_id].set(xlim=(-0.7, len(feats_imm)-0.3))\n",
    "    axs_bar[row_id, col_id].set_title(f\"{group} ({len(ids_groups[group])})\")\n",
    "    axs_bar[row_id, col_id].set_xticklabels(axs_bar[row_id, col_id].get_xticklabels(), rotation=90)\n",
    "    axs_bar[row_id, col_id].set_xlabel(f\"\")\n",
    "\n",
    "    df_nan_smpls = imm_w_nans.loc[ids_groups[group], feats_imm].isna().sum(axis=1).to_frame(name=\"Features with NaNs\")\n",
    "    \n",
    "    hist_bins = np.linspace(0, len(feats_imm), len(feats_imm) + 1)\n",
    "    histplot = sns.histplot(\n",
    "        data=df_nan_smpls,\n",
    "        discrete=True,\n",
    "        edgecolor='k',\n",
    "        linewidth=1,\n",
    "        x=\"Features with NaNs\",\n",
    "        color=colors_groups[group],\n",
    "        ax=axs_hist[row_id, col_id],\n",
    "    )\n",
    "    axs_hist[row_id, col_id].set(xlim=(-0.6, len(feats_imm)+0.6))\n",
    "    axs_hist[row_id, col_id].set_title(f\"{group} ({len(ids_groups[group])})\")\n",
    "    axs_hist[row_id, col_id].set_ylabel(f\"Number of samples\")\n",
    "    axs_hist[row_id, col_id].set_xlabel(f\"\")\n",
    "\n",
    "axs_hist[n_rows - 1, n_cols - 1].axis('off')\n",
    "axs_bar[n_rows - 1, n_cols - 1].axis('off')\n",
    "\n",
    "fig_bar.tight_layout() \n",
    "fig_bar.savefig(f\"{path}/01_new_data_05_2025/nans/feats.png\", bbox_inches='tight', dpi=200)\n",
    "fig_bar.savefig(f\"{path}/01_new_data_05_2025/nans/feats.pdf\", bbox_inches='tight')\n",
    "plt.close(fig_bar)\n",
    "\n",
    "with pd.ExcelWriter(f'{path}/01_new_data_05_2025/nans/feats.xlsx', engine='xlsxwriter') as writer:\n",
    "    for group_id, group in enumerate(groups):\n",
    "        dfs_nan_feats[group].to_excel(writer, sheet_name=group)\n",
    "\n",
    "fig_hist.tight_layout()    \n",
    "fig_hist.savefig(f\"{path}/01_new_data_05_2025/nans/samples.png\", bbox_inches='tight', dpi=200)\n",
    "fig_hist.savefig(f\"{path}/01_new_data_05_2025/nans/samples.pdf\", bbox_inches='tight')\n",
    "plt.close(fig_hist)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "sns.set_theme(style='whitegrid')\n",
    "barplot = sns.barplot(\n",
    "    data=df_nan_feats_by_group,\n",
    "    y=df_nan_feats_by_group.index,\n",
    "    x=f\"% of NaNs\",\n",
    "    edgecolor='black',\n",
    "    palette=colors_groups,\n",
    "    dodge=False,\n",
    "    orient='h',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_ylabel(f\"\")\n",
    "for x in barplot.containers:\n",
    "    barplot.bar_label(x, fmt=\"%.1f\", padding=2.0)\n",
    "plt.savefig(f\"{path}/01_new_data_05_2025/nans/global.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/01_new_data_05_2025/nans/global.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/01_new_data_05_2025/technical_duplicates\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tech_dupl_samples_count = imm.loc[imm['Has technical duplicates?'] == True, 'Subject ID'].value_counts().to_frame(name='Count').sort_values(by=['Count'], ascending=[False])\n",
    "tech_dupl_samples_count.to_excel(f\"{path}/01_new_data_05_2025/technical_duplicates/tech_dupl_samples_count.xlsx\")\n",
    "\n",
    "samples_techdupl = imm.loc[imm['Has technical duplicates?'] == True, 'Subject ID'].unique()\n",
    "df_tech_dupl = pd.DataFrame(index=samples_techdupl, columns=feats_imm_slctd)\n",
    "df_tech_dupl_mean = pd.DataFrame(index=feats_imm_slctd, columns=['Mean'])\n",
    "for f in feats_imm_slctd:\n",
    "    for sample_td in samples_techdupl:\n",
    "        df_tech_dupl.at[sample_td, f] = stats.variation(imm.loc[(imm['Has technical duplicates?'] == True) & (imm['Subject ID'] == sample_td), f\"{f}\"], ddof=1)\n",
    "    df_tech_dupl_mean.at[f, 'Mean'] = np.mean(df_tech_dupl.loc[:, f].values)\n",
    "df_tech_dupl_mean.sort_values(by=['Mean'], ascending=[False], inplace=True)\n",
    "df_tech_dupl['Subject ID'] = df_tech_dupl.index\n",
    "df_tech_dupl_melt = df_tech_dupl.melt(id_vars='Subject ID', value_vars=df_tech_dupl_mean.index.values, var_name='Immunomarkers', value_name='Coefficient of variation (CV)')\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig, ax = plt.subplots(figsize=(4, 10), layout='constrained')\n",
    "barplot = sns.barplot(\n",
    "    df_tech_dupl_melt,\n",
    "    y=\"Immunomarkers\",\n",
    "    x=\"Coefficient of variation (CV)\",\n",
    "    hue=\"Immunomarkers\",\n",
    "    palette=feats_palette,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_ylabel('')\n",
    "plt.savefig(f\"{path}/01_new_data_05_2025/technical_duplicates/barplot_cv.pdf\", bbox_inches='tight')\n",
    "plt.savefig(f\"{path}/01_new_data_05_2025/technical_duplicates/barplot_cv.png\", bbox_inches='tight', dpi=200)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/01_new_data_05_2025/repeated_measures\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_repmes = imm.loc[imm['2025 Repeated Measures?'] == True, :]\n",
    "df_repmes['2025 Repeated Measures Time'].replace({0: 'Old', 1: 'New'}, inplace=True)\n",
    "samples_repmes = {\n",
    "    'Mirny': df_repmes.loc[df_repmes['Group'] == 'Old Mirny', 'Subject ID'].values,\n",
    "    'FMBA': df_repmes.loc[df_repmes['Group'] == 'Old FMBA', 'Subject ID'].values,\n",
    "}\n",
    "\n",
    "for subset_name, subset_samples in samples_repmes.items():\n",
    "    df_repmes_subset = df_repmes.loc[df_repmes['Subject ID'].isin(subset_samples), :]\n",
    "    df_repmes_subset.to_excel(f\"{path}/01_new_data_05_2025/repeated_measures/data_{subset_name}.xlsx\")\n",
    "    df_stat = pd.DataFrame(index=list(feats_imm_slctd))\n",
    "    \n",
    "    for feat in feats_imm_slctd:\n",
    "        df_pivot = df_repmes_subset.pivot(index='Subject ID', columns='2025 Repeated Measures Time', values=feat)\n",
    "        diff = df_pivot.loc[:, 'New'].values - df_pivot.loc[:, 'Old'].values\n",
    "        if np.linalg.norm(diff) > 0:\n",
    "            res = stats.wilcoxon(\n",
    "                x=df_pivot.loc[:, 'Old'].values,\n",
    "                y=df_pivot.loc[:, 'New'].values,\n",
    "                alternative='two-sided'\n",
    "            )\n",
    "            df_stat.at[feat, \"wlxn_pval\"] =  res.pvalue\n",
    "        else:\n",
    "            df_stat.at[feat, \"wlxn_pval\"] = 1.0\n",
    "    \n",
    "    _, df_stat.loc[feats_imm_slctd, \"wlxn_pval_fdr_bh\"], _, _ = multipletests(df_stat.loc[feats_imm_slctd, \"wlxn_pval\"], 0.05, method='fdr_bh')\n",
    "    df_stat.to_excel(f\"{path}/01_new_data_05_2025/repeated_measures/{subset_name}.xlsx\", index_label='Features')\n",
    "    \n",
    "    df_fig = df_stat.loc[feats_imm_slctd, :]\n",
    "    df_fig.sort_values([f\"wlxn_pval\"], ascending=[True], inplace=True)\n",
    "    df_fig['wlxn_pval_fdr_bh_log'] = -np.log10(df_fig['wlxn_pval_fdr_bh'])\n",
    "    df_fig['color'] = 'pink'\n",
    "    df_fig.loc[df_fig['wlxn_pval_fdr_bh'] < 0.05, 'color'] = 'red'\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3, 16))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    barplot = sns.barplot(\n",
    "        data=df_fig,\n",
    "        y=df_fig.index.values,\n",
    "        x='wlxn_pval_fdr_bh_log',\n",
    "        edgecolor='black',\n",
    "        palette=df_fig['color'].values,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel(r\"$-\\log_{10}(\\mathrm{p-value})$\", fontsize=18)\n",
    "    ax.set_ylabel('', fontsize=20)\n",
    "    ax.set_xticklabels([f\"{int(tick):d}\" for tick in ax.get_xticks()], fontsize=16)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize = 16)\n",
    "    plt.savefig(f\"{path}/01_new_data_05_2025/repeated_measures/{subset_name}_barplot_wlxn.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path}/01_new_data_05_2025/repeated_measures/{subset_name}_barplot_wlxn.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    n_cols = 4\n",
    "    n_rows = 8\n",
    "    fig_width = 12\n",
    "    fig_height = 16\n",
    "\n",
    "    colors_reps = {\n",
    "        \"Old\": 'crimson',\n",
    "        \"New\": 'dodgerblue',\n",
    "    }\n",
    "    \n",
    "    sns.set_theme(style='ticks')\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height), gridspec_kw={})\n",
    "\n",
    "    df_stat.sort_values([f\"wlxn_pval\"], ascending=[True], inplace=True)\n",
    "    feats_sorted = df_stat.index.values\n",
    "    \n",
    "    samples_colors_raw = distinctipy.get_colors(len(subset_samples), [mcolors.hex2color(mcolors.CSS4_COLORS['black']), mcolors.hex2color(mcolors.CSS4_COLORS['white'])], rng=1899, pastel_factor=0.0)\n",
    "    samples_palette = {x: samples_colors_raw[x_id] for x_id, x in enumerate(subset_samples)}\n",
    "\n",
    "    for f_id, f in enumerate(feats_sorted):\n",
    "        row_id, col_id = divmod(f_id, n_cols)\n",
    "        \n",
    "        sns.scatterplot(\n",
    "            data=df_repmes_subset,\n",
    "            x='2025 Repeated Measures Time',\n",
    "            y=f,\n",
    "            hue='Subject ID',\n",
    "            edgecolor=\"k\",\n",
    "            linewidth=0.001,\n",
    "            palette=samples_palette,\n",
    "            hue_order=list(samples_palette.keys()),\n",
    "            alpha=0.75,\n",
    "            s=100,\n",
    "            legend=False,\n",
    "            ax=axs[row_id, col_id]\n",
    "        )\n",
    "        sns.lineplot(\n",
    "            data=df_repmes_subset,\n",
    "            x='2025 Repeated Measures Time',\n",
    "            y=f,\n",
    "            hue='Subject ID',\n",
    "            palette=samples_palette,\n",
    "            hue_order=list(samples_palette.keys()),\n",
    "            legend=False,\n",
    "            ax=axs[row_id, col_id]\n",
    "        )\n",
    "        \n",
    "        axs[row_id, col_id].set_xlabel('')\n",
    "        pval = df_stat.at[f, \"wlxn_pval_fdr_bh\"]\n",
    "        axs[row_id, col_id].set_title(f'{pval:.2e}')\n",
    "\n",
    "    fig.tight_layout()    \n",
    "    plt.savefig(f\"{path}/01_new_data_05_2025/repeated_measures/{subset_name}_feats.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path}/01_new_data_05_2025/repeated_measures/{subset_name}_feats.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old vs New by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "samples_old_vs_new = {\n",
    "    'Central': {\n",
    "        'Old': imm.index[imm['Group detailed'] == 'Old Central'].values,\n",
    "        'New': imm.index[imm['Group detailed'] == 'New 2025 UNN'].values\n",
    "    },\n",
    "    'Mirny': {\n",
    "        'Old': imm.index[imm['Group detailed'] == 'Old Mirny'].values,\n",
    "        'New': imm.index[imm['Group detailed'] == 'New 2025 Mirny'].values\n",
    "    },\n",
    "    'FMBA': {\n",
    "        'Old': imm.index[imm['Group detailed'] == 'Old FMBA'].values,\n",
    "        'New': imm.index[imm['Group detailed'] == 'New 2025 FMBA'].values\n",
    "    },\n",
    "}\n",
    "\n",
    "colors_samples_groups = {\n",
    "    'Central': 'gold',\n",
    "    'Mirny': 'crimson',\n",
    "    'FMBA': 'dodgerblue',\n",
    "}\n",
    "\n",
    "colors_samples_old_vs_new = {\n",
    "    'Central': {\n",
    "        'Old': 'goldenrod',\n",
    "        'New': 'yellow'\n",
    "    },\n",
    "    'Mirny': {\n",
    "        'Old': 'firebrick',\n",
    "        'New': 'tomato'\n",
    "    },\n",
    "    'FMBA': {\n",
    "        'Old': 'mediumblue',\n",
    "        'New': 'deepskyblue'\n",
    "    },\n",
    "}\n",
    "\n",
    "for group_name, group_samples_dict in samples_old_vs_new.items():\n",
    "    df_imm_curr = imm.loc[list(set.union(*(set(group_samples) for group, group_samples in group_samples_dict.items()))), ['Age', 'SImAge', '|SImAge acceleration|', 'SImAge acceleration'] + list(feats_imm_slctd)]\n",
    "    for group, group_samples in group_samples_dict.items():\n",
    "        df_imm_curr.loc[group_samples, group_name] = group\n",
    "    df_imm_curr.to_excel(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_data.xlsx\")\n",
    "    \n",
    "    hist_bins = np.linspace(5, 115, 23)\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    histplot = sns.histplot(\n",
    "        data=df_imm_curr,\n",
    "        bins=hist_bins,\n",
    "        edgecolor='k',\n",
    "        linewidth=1,\n",
    "        x=\"Age\",\n",
    "        hue=group_name,\n",
    "        palette=colors_samples_old_vs_new[group_name],\n",
    "        ax=ax\n",
    "    )\n",
    "    histplot.set(xlim=(0, 120))\n",
    "    plt.savefig(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_hist_age.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_hist_age.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    df_stat = pd.DataFrame(index=feats_imm_slctd)\n",
    "    for f_if, f in enumerate(feats_imm_slctd):\n",
    "        for group, group_samples in group_samples_dict.items():\n",
    "            df_stat.at[f, f\"Spearman (Age) for {group}\"] = stats.spearmanr(\n",
    "                df_imm_curr.loc[group_samples, 'Age'].values,\n",
    "                df_imm_curr.loc[group_samples, f].values\n",
    "            ).statistic\n",
    "            df_stat.at[f, f\"Pearson (Age) for {group}\"] = stats.pearsonr(\n",
    "                df_imm_curr.loc[group_samples, 'Age'].values,\n",
    "                df_imm_curr.loc[group_samples, f].values\n",
    "            ).statistic\n",
    "        _, df_stat.at[f, \"mannwhitneyu_pval\"] = mannwhitneyu(df_imm_curr.loc[df_imm_curr[group_name] == 'New', f].values, df_imm_curr.loc[df_imm_curr[group_name] == 'Old', f].values, alternative='two-sided')\n",
    "        _, df_stat.at[f, \"levene_pval\"] = levene(df_imm_curr.loc[df_imm_curr[group_name] == 'New', f].values, df_imm_curr.loc[df_imm_curr[group_name] == 'Old', f].values)\n",
    "        regcov = smf.ols(formula=f\"Q('{f}') ~ Q('{group_name}') + Age\", data=df_imm_curr).fit()\n",
    "        reg_sum = regcov.summary2().tables[1]\n",
    "        pvals_cols = reg_sum.index[reg_sum.index.str.contains(group_name)].values\n",
    "        for pval_col_id, pval_col in enumerate(pvals_cols):\n",
    "            df_stat.at[f, f\"ancova_{pval_col}_pval\"] = reg_sum.at[pval_col, 'P>|t|']\n",
    "    _, df_stat.loc[feats_imm_slctd, \"mannwhitneyu_pval_fdr_bh\"], _, _ = multipletests(df_stat.loc[feats_imm_slctd, \"mannwhitneyu_pval\"].values, 0.05, method='fdr_bh')\n",
    "    _, df_stat.loc[feats_imm_slctd, \"levene_pval_fdr_bh\"], _, _ = multipletests(df_stat.loc[feats_imm_slctd, \"levene_pval\"].values, 0.05, method='fdr_bh')\n",
    "    pvals_cols_ancova = df_stat.columns[df_stat.columns.str.contains(group_name)].values\n",
    "    for pval_col in pvals_cols_ancova:\n",
    "        _, df_stat.loc[feats_imm_slctd, f\"{pval_col}_fdr_bh\"], _, _ = multipletests(df_stat.loc[feats_imm_slctd, pval_col].values, 0.05, method='fdr_bh')\n",
    "    df_stat.sort_values([f\"mannwhitneyu_pval\"], ascending=[True], inplace=True)\n",
    "    df_stat.to_excel(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_stat.xlsx\")\n",
    "    \n",
    "    for stat_test in [x.replace('_pval', '') for x in pvals_cols_ancova] + ['mannwhitneyu', 'levene']:\n",
    "        df_fig = df_stat.copy()\n",
    "        df_fig.sort_values([f\"{stat_test}_pval\"], ascending=[True], inplace=True)\n",
    "        df_fig['Features'] = df_fig.index\n",
    "        df_fig[f'{stat_test}_pval_fdr_bh_log'] = -np.log10(df_fig[f'{stat_test}_pval_fdr_bh'])\n",
    "        df_fig['color'] = 'white'\n",
    "        df_fig.loc[df_fig[f'{stat_test}_pval_fdr_bh'] < 0.05, 'color'] = colors_samples_groups[group_name]\n",
    "        sns.set_theme(style='ticks')\n",
    "        fig, ax = plt.subplots(figsize=(3, df_fig.shape[0] * 0.5))\n",
    "        barplot = sns.barplot(\n",
    "            data=df_fig,\n",
    "            y='Features',\n",
    "            x=f'{stat_test}_pval_fdr_bh_log',\n",
    "            edgecolor='black',\n",
    "            palette=df_fig['color'].values,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_xlabel(r\"$-\\log_{10}(\\mathrm{p-value})$\")\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position('top')\n",
    "        ax.set_ylabel('')\n",
    "        plt.savefig(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_{stat_test}.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_{stat_test}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "    for corr_type in ['Spearman', 'Pearson']:\n",
    "        df_fig = df_stat.copy()\n",
    "        df_fig['Features'] = df_fig.index\n",
    "        df_fig = df_fig.melt(id_vars='Features', value_vars=[f\"{corr_type} (Age) for {group}\" for group in ['Old', 'New']], var_name='Group', value_name=fr\"{corr_type} $\\rho$\")\n",
    "        df_fig['Group'].replace({f\"{corr_type} (Age) for {group}\": f\"{group}\" for group in ['Old', 'New']}, inplace=True)\n",
    "        df_fig.sort_values([fr\"{corr_type} $\\rho$\"], ascending=[False], inplace=True)\n",
    "        sns.set_theme(style='ticks')\n",
    "        fig, ax = plt.subplots(figsize=(3, df_fig.shape[0] * 0.15))\n",
    "        barplot = sns.barplot(\n",
    "            data=df_fig,\n",
    "            y='Features',\n",
    "            x=fr\"{corr_type} $\\rho$\",\n",
    "            edgecolor='black',\n",
    "            palette=colors_samples_old_vs_new[group_name],\n",
    "            hue='Group',\n",
    "            hue_order=['Old', 'New'],\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position('top')\n",
    "        ax.set_ylabel('')\n",
    "        plt.savefig(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_{corr_type}.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_{corr_type}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "    sns.set_theme(style='ticks')\n",
    "    fig = plt.figure(\n",
    "        figsize=(24, 20),\n",
    "        layout=\"constrained\"\n",
    "    )\n",
    "    subfigs = fig.subfigures(\n",
    "        nrows=8,\n",
    "        ncols=4,\n",
    "        wspace=0.01,\n",
    "        hspace=0.01,\n",
    "    )\n",
    "    feats_imm_slctd_sorted = df_stat.sort_values([f'Pearson (Age) for Old'], ascending=[False]).index.values\n",
    "    for feat_id, feat in enumerate(feats_imm_slctd_sorted):\n",
    "        row_id, col_id = divmod(feat_id, 4)\n",
    "\n",
    "        axs = subfigs[row_id, col_id].subplot_mosaic(\n",
    "            [\n",
    "                ['11', '12'],\n",
    "                ['21', '22'],\n",
    "            ],\n",
    "            height_ratios=[1, 4],\n",
    "            width_ratios=[3, 1.5],\n",
    "            gridspec_kw={\n",
    "                # \"bottom\": 0.14,\n",
    "                # \"top\": 0.95,\n",
    "                # \"left\": 0.1,\n",
    "                # \"right\": 0.5,\n",
    "                \"wspace\": 0.01,\n",
    "                \"hspace\": 0.01,\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        ds_table_age = pd.DataFrame(index=[fr\"Pearson $\\rho$\", fr\"Spearman $\\rho$\"], columns=['Old', 'New'])\n",
    "        for corr_type in ['Spearman', 'Pearson']:\n",
    "            for group in ['Old', 'New']:\n",
    "                cell_value = df_stat.at[feat, f'{corr_type} (Age) for {group}']\n",
    "                ds_table_age.at[fr\"{corr_type} $\\rho$\", group] = f\"{cell_value:0.2f}\"\n",
    "        col_defs = [\n",
    "            ColumnDefinition(\n",
    "                name=\"index\",\n",
    "                title='Correlation with Age',\n",
    "                textprops={\"ha\": \"left\"},\n",
    "                width=4.5,\n",
    "            ),\n",
    "            ColumnDefinition(\n",
    "                name='Old',\n",
    "                title='Old',\n",
    "                textprops={\"ha\": \"center\"},\n",
    "                width=2.0,\n",
    "            ),\n",
    "            ColumnDefinition(\n",
    "                name='New',\n",
    "                title='New',\n",
    "                textprops={\"ha\": \"center\"},\n",
    "                width=2.0,\n",
    "            ),\n",
    "        ]\n",
    "        table = Table(\n",
    "            ds_table_age,\n",
    "            column_definitions=col_defs,\n",
    "            row_dividers=True,\n",
    "            footer_divider=False,\n",
    "            ax=axs['11'],\n",
    "            textprops={\"fontsize\": 6},\n",
    "            row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "            col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "            column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        ).autoset_fontcolors(colnames=['Old', 'New'])\n",
    "        \n",
    "        ds_table_groups = pd.DataFrame(index=[\"Mann-Whitney\", \"Levene\", 'ANCOVA'], columns=['p-values (FDR)'])\n",
    "        mannwhitneyu_pval = df_stat.loc[feat, 'mannwhitneyu_pval_fdr_bh']\n",
    "        levene_pval = df_stat.loc[feat, 'levene_pval_fdr_bh']\n",
    "        pvals_cols_ancova = df_stat.columns[df_stat.columns.str.contains(group_name)].values\n",
    "        ancova_pval = df_stat.loc[feat, pvals_cols_ancova[0]]\n",
    "        ds_table_groups.at[\"Mann-Whitney\", \"p-values (FDR)\"] = f\"{mannwhitneyu_pval:0.2e}\"\n",
    "        ds_table_groups.at[\"Levene\", \"p-values (FDR)\"] = f\"{levene_pval:0.2e}\"\n",
    "        ds_table_groups.at[\"ANCOVA\", \"p-values (FDR)\"] = f\"{ancova_pval:0.2e}\"\n",
    "        col_defs = [\n",
    "            ColumnDefinition(\n",
    "                name=\"index\",\n",
    "                title='Test',\n",
    "                textprops={\"ha\": \"left\"},\n",
    "                width=4.5,\n",
    "            ),\n",
    "            ColumnDefinition(\n",
    "                name='p-values (FDR)',\n",
    "                title='p-values (FDR)',\n",
    "                textprops={\"ha\": \"center\"},\n",
    "                width=2.0,\n",
    "            ),\n",
    "        ]\n",
    "        table = Table(\n",
    "            ds_table_groups,\n",
    "            column_definitions=col_defs,\n",
    "            row_dividers=True,\n",
    "            footer_divider=False,\n",
    "            ax=axs['12'],\n",
    "            textprops={\"fontsize\": 5},\n",
    "            row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "            col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "            column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        ).autoset_fontcolors(colnames=['p-values (FDR)'])\n",
    "        \n",
    "        for group in group_samples_dict.keys():    \n",
    "            regplot = sns.regplot(\n",
    "                data=df_imm_curr.loc[df_imm_curr[group_name] == group, :],\n",
    "                x='Age',\n",
    "                y=feat,\n",
    "                label=group,\n",
    "                color=colors_samples_old_vs_new[group_name][group],\n",
    "                scatter_kws=dict(\n",
    "                    linewidth=0.5,\n",
    "                    alpha=0.75,\n",
    "                    edgecolor=\"k\",\n",
    "                    s=16,\n",
    "                ),\n",
    "                ax=axs['21']\n",
    "            )\n",
    "        \n",
    "        sns.violinplot(\n",
    "            data=df_imm_curr,\n",
    "            x=group_name,\n",
    "            y=feat,\n",
    "            hue=group_name,\n",
    "            palette=colors_samples_old_vs_new[group_name],\n",
    "            density_norm='width',\n",
    "            order=['Old', 'New'],\n",
    "            saturation=0.75,\n",
    "            linewidth=1.0,\n",
    "            ax=axs['22'],\n",
    "            legend=False,\n",
    "            cut=0,\n",
    "        )\n",
    "        axs['22'].set_ylabel(feat)\n",
    "        axs['22'].set_xlabel(\"\")\n",
    "\n",
    "    fig.savefig(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_feats.png\", bbox_inches='tight', dpi=200)\n",
    "    fig.savefig(f\"{path}/01_new_data_05_2025/old_vs_new_by_groups/{group_name}_feats.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different groups in new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/01_new_data_05_2025/different_groups_in_new_data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "group_samples_dict = {\n",
    "    'Central': imm.index[imm['Group detailed'] == 'New 2025 UNN'].values,\n",
    "    'Mirny': imm.index[imm['Group detailed'] == 'New 2025 Mirny'].values,\n",
    "    'FMBA': imm.index[imm['Group detailed'] == 'New 2025 FMBA'].values\n",
    "}\n",
    "\n",
    "colors_samples_groups = {\n",
    "    'Central': 'gold',\n",
    "    'Mirny': 'crimson',\n",
    "    'FMBA': 'dodgerblue',\n",
    "}\n",
    "\n",
    "df_imm_curr = imm.loc[list(set.union(*(set(sg) for g, sg in group_samples_dict.items()))), ['Age', 'SImAge', '|SImAge acceleration|', 'SImAge acceleration'] + list(feats_imm_slctd)]\n",
    "for group, group_samples in group_samples_dict.items():\n",
    "    df_imm_curr.loc[group_samples, 'Group'] = group\n",
    "df_imm_curr.to_excel(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/data.xlsx\")\n",
    "\n",
    "hist_bins = np.linspace(5, 115, 23)\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "histplot = sns.histplot(\n",
    "    data=df_imm_curr,\n",
    "    bins=hist_bins,\n",
    "    edgecolor='k',\n",
    "    linewidth=1,\n",
    "    x=\"Age\",\n",
    "    hue='Group',\n",
    "    palette=colors_samples_groups,\n",
    "    ax=ax\n",
    ")\n",
    "histplot.set(xlim=(0, 120))\n",
    "plt.savefig(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/hist_age.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/hist_age.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "\n",
    "df_stat = pd.DataFrame(index=feats_imm_slctd)\n",
    "for f_if, f in enumerate(feats_imm_slctd):\n",
    "    \n",
    "    for group, group_samples in group_samples_dict.items():\n",
    "        df_stat.at[f, f\"Spearman (Age) for {group}\"] = stats.spearmanr(\n",
    "            df_imm_curr.loc[group_samples, 'Age'].values,\n",
    "            df_imm_curr.loc[group_samples, f].values\n",
    "        ).statistic\n",
    "        df_stat.at[f, f\"Pearson (Age) for {group}\"] = stats.pearsonr(\n",
    "            df_imm_curr.loc[group_samples, 'Age'].values,\n",
    "            df_imm_curr.loc[group_samples, f].values\n",
    "        ).statistic\n",
    "        \n",
    "    for pairs in [['Central', 'Mirny'], ['Central', 'FMBA'], ['Mirny', 'FMBA']]:\n",
    "        _, df_stat.at[f, f\"mw_{pairs[0]}_vs_{pairs[1]}\"] = mannwhitneyu(df_imm_curr.loc[df_imm_curr['Group'] == pairs[0], f].values, df_imm_curr.loc[df_imm_curr['Group'] == pairs[1], f].values, alternative='two-sided')\n",
    "        _, df_stat.at[f, f\"lv_{pairs[0]}_vs_{pairs[1]}\"] = levene(df_imm_curr.loc[df_imm_curr['Group'] == pairs[0], f].values, df_imm_curr.loc[df_imm_curr['Group'] == pairs[1], f].values)\n",
    "        regcov = smf.ols(formula=f\"Q('{f}') ~ Group + Age\", data=df_imm_curr.loc[df_imm_curr['Group'].isin(pairs), :]).fit()\n",
    "        reg_sum = regcov.summary2().tables[1]\n",
    "        pvals_cols = reg_sum.index[reg_sum.index.str.contains('Group')].values\n",
    "        for pval_col_id, pval_col in enumerate(pvals_cols):\n",
    "            df_stat.at[f, f\"ancova_{pairs[0]}_vs_{pairs[1]}\"] = reg_sum.at[pval_col, 'P>|t|']\n",
    "    \n",
    "for pairs in [['Central', 'Mirny'], ['Central', 'FMBA'], ['Mirny', 'FMBA']]:   \n",
    "    _, df_stat.loc[feats_imm_slctd, f\"mw_{pairs[0]}_vs_{pairs[1]}_fdr_bh\"], _, _ = multipletests(df_stat.loc[feats_imm_slctd, f\"mw_{pairs[0]}_vs_{pairs[1]}\"].values, 0.05, method='fdr_bh')\n",
    "    _, df_stat.loc[feats_imm_slctd, f\"lv_{pairs[0]}_vs_{pairs[1]}_fdr_bh\"], _, _ = multipletests(df_stat.loc[feats_imm_slctd, f\"lv_{pairs[0]}_vs_{pairs[1]}\"].values, 0.05, method='fdr_bh')\n",
    "    _, df_stat.loc[feats_imm_slctd, f\"ancova_{pairs[0]}_vs_{pairs[1]}_fdr_bh\"], _, _ = multipletests(df_stat.loc[feats_imm_slctd, f\"ancova_{pairs[0]}_vs_{pairs[1]}\"].values, 0.05, method='fdr_bh')\n",
    "df_stat.to_excel(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/stat.xlsx\")\n",
    "\n",
    "for stat_test in ['mw', 'lv', 'ancova']:\n",
    "    for pairs in [['Central', 'Mirny'], ['Central', 'FMBA'], ['Mirny', 'FMBA']]:\n",
    "        df_fig = df_stat.copy()\n",
    "        df_fig.sort_values([f\"{stat_test}_{pairs[0]}_vs_{pairs[1]}\"], ascending=[True], inplace=True)\n",
    "        df_fig['Features'] = df_fig.index\n",
    "        df_fig[f\"{stat_test}_{pairs[0]}_vs_{pairs[1]}_fdr_bh_log\"] = -np.log10(df_fig[f\"{stat_test}_{pairs[0]}_vs_{pairs[1]}_fdr_bh\"])\n",
    "        df_fig['color'] = 'white'\n",
    "        df_fig.loc[df_fig[f\"{stat_test}_{pairs[0]}_vs_{pairs[1]}_fdr_bh\"] < 0.05, 'color'] = 'red'\n",
    "        sns.set_theme(style='ticks')\n",
    "        fig, ax = plt.subplots(figsize=(3, df_fig.shape[0] * 0.5))\n",
    "        barplot = sns.barplot(\n",
    "            data=df_fig,\n",
    "            y='Features',\n",
    "            x=f\"{stat_test}_{pairs[0]}_vs_{pairs[1]}_fdr_bh_log\",\n",
    "            edgecolor='black',\n",
    "            palette=df_fig['color'].values,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_xlabel(r\"$-\\log_{10}(\\mathrm{p-value})$\")\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position('top')\n",
    "        ax.set_ylabel('')\n",
    "        plt.savefig(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/{pairs[0]}_vs_{pairs[1]}_{stat_test}.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/{pairs[0]}_vs_{pairs[1]}_{stat_test}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        \n",
    "for corr_type in ['Spearman', 'Pearson']:\n",
    "    df_fig = df_stat.copy()\n",
    "    df_fig['Features'] = df_fig.index\n",
    "    df_fig = df_fig.melt(id_vars='Features', value_vars=[f\"{corr_type} (Age) for {group}\" for group in ['Central', 'Mirny', 'FMBA']], var_name='Group', value_name=fr\"{corr_type} $\\rho$\")\n",
    "    df_fig['Group'].replace({f\"{corr_type} (Age) for {group}\": f\"{group}\" for group in ['Central', 'Mirny', 'FMBA']}, inplace=True)\n",
    "    df_fig.sort_values([fr\"{corr_type} $\\rho$\"], ascending=[False], inplace=True)\n",
    "    sns.set_theme(style='ticks')\n",
    "    fig, ax = plt.subplots(figsize=(3, df_fig.shape[0] * 0.15))\n",
    "    barplot = sns.barplot(\n",
    "        data=df_fig,\n",
    "        y='Features',\n",
    "        x=fr\"{corr_type} $\\rho$\",\n",
    "        edgecolor='black',\n",
    "        palette=colors_samples_groups,\n",
    "        hue='Group',\n",
    "        hue_order=['Central', 'Mirny', 'FMBA'],\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.set_ylabel('')\n",
    "    plt.savefig(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/{corr_type}.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/{corr_type}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "      \n",
    "sns.set_theme(style='ticks')\n",
    "fig = plt.figure(\n",
    "    figsize=(24, 20),\n",
    "    layout=\"constrained\"\n",
    ")\n",
    "subfigs = fig.subfigures(\n",
    "    nrows=8,\n",
    "    ncols=4,\n",
    "    wspace=0.01,\n",
    "    hspace=0.01,\n",
    ")\n",
    "feats_imm_slctd_sorted = df_stat.sort_values([f'Pearson (Age) for Central'], ascending=[False]).index.values\n",
    "for feat_id, feat in enumerate(feats_imm_slctd_sorted):\n",
    "    row_id, col_id = divmod(feat_id, 4)\n",
    "\n",
    "    axs = subfigs[row_id, col_id].subplot_mosaic(\n",
    "        [\n",
    "            ['11', '12'],\n",
    "            ['21', '22'],\n",
    "        ],\n",
    "        height_ratios=[1, 4],\n",
    "        width_ratios=[3, 1.5],\n",
    "        gridspec_kw={\n",
    "            # \"bottom\": 0.14,\n",
    "            # \"top\": 0.95,\n",
    "            # \"left\": 0.1,\n",
    "            # \"right\": 0.5,\n",
    "            \"wspace\": 0.01,\n",
    "            \"hspace\": 0.01,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    ds_table_age = pd.DataFrame(index=[fr\"Pearson $\\rho$\", fr\"Spearman $\\rho$\"], columns=['Central', 'Mirny', 'FMBA'])\n",
    "    for corr_type in ['Spearman', 'Pearson']:\n",
    "        for group in ['Central', 'Mirny', 'FMBA']:\n",
    "            cell_value = df_stat.at[feat, f'{corr_type} (Age) for {group}']\n",
    "            ds_table_age.at[fr\"{corr_type} $\\rho$\", group] = f\"{cell_value:0.2f}\"\n",
    "    col_defs = [\n",
    "        ColumnDefinition(\n",
    "            name=\"index\",\n",
    "            title='Correlation with Age',\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=4.5,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name='Central',\n",
    "            title='Central',\n",
    "            textprops={\"ha\": \"center\"},\n",
    "            width=2.0,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name='Mirny',\n",
    "            title='Mirny',\n",
    "            textprops={\"ha\": \"center\"},\n",
    "            width=2.0,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name='FMBA',\n",
    "            title='FMBA',\n",
    "            textprops={\"ha\": \"center\"},\n",
    "            width=2.0,\n",
    "        ),\n",
    "    ]\n",
    "    table = Table(\n",
    "        ds_table_age,\n",
    "        column_definitions=col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        ax=axs['11'],\n",
    "        textprops={\"fontsize\": 6},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=['Central', 'Mirny', 'FMBA'])\n",
    "    \n",
    "    ds_table_groups = pd.DataFrame(index=[\"Mann-Whitney\", \"Levene\", 'ANCOVA'], columns=['Central\\nvs\\nMirny', 'Central\\nvs\\nFMBA', 'Mirny\\nvs\\nFMBA'])\n",
    "    for pairs in [['Central', 'Mirny'], ['Central', 'FMBA'], ['Mirny', 'FMBA']]:\n",
    "        mannwhitneyu_pval = df_stat.loc[feat, f\"mw_{pairs[0]}_vs_{pairs[1]}_fdr_bh\"]\n",
    "        levene_pval = df_stat.loc[feat, f\"lv_{pairs[0]}_vs_{pairs[1]}_fdr_bh\"]\n",
    "        ancova_pval = df_stat.loc[feat, f\"ancova_{pairs[0]}_vs_{pairs[1]}_fdr_bh\"]\n",
    "        ds_table_groups.at[\"Mann-Whitney\", f\"{pairs[0]}\\nvs\\n{pairs[1]}\"] = f\"{mannwhitneyu_pval:0.2e}\"\n",
    "        ds_table_groups.at[\"Levene\", f\"{pairs[0]}\\nvs\\n{pairs[1]}\"] = f\"{levene_pval:0.2e}\"\n",
    "        ds_table_groups.at[\"ANCOVA\", f\"{pairs[0]}\\nvs\\n{pairs[1]}\"] = f\"{ancova_pval:0.2e}\"\n",
    "    col_defs = [\n",
    "        ColumnDefinition(\n",
    "            name=\"index\",\n",
    "            title='Test',\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=2.5,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name='Central\\nvs\\nMirny',\n",
    "            title='Central-Mirny',\n",
    "            textprops={\"ha\": \"center\"},\n",
    "            width=2.7,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name='Central\\nvs\\nFMBA',\n",
    "            title='Central-FMBA',\n",
    "            textprops={\"ha\": \"center\"},\n",
    "            width=2.7,\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name='Mirny\\nvs\\nFMBA',\n",
    "            title='Mirny-FMBA',\n",
    "            textprops={\"ha\": \"center\"},\n",
    "            width=2.7,\n",
    "        ),\n",
    "    ]\n",
    "    table = Table(\n",
    "        ds_table_groups,\n",
    "        column_definitions=col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        ax=axs['12'],\n",
    "        textprops={\"fontsize\": 4},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=['Central\\nvs\\nMirny', 'Central\\nvs\\nFMBA', 'Mirny\\nvs\\nFMBA'])\n",
    "    \n",
    "    for group in group_samples_dict.keys():    \n",
    "        regplot = sns.regplot(\n",
    "            data=df_imm_curr.loc[df_imm_curr['Group'] == group, :],\n",
    "            x='Age',\n",
    "            y=feat,\n",
    "            label=group,\n",
    "            color=colors_samples_groups[group],\n",
    "            scatter_kws=dict(\n",
    "                linewidth=0.5,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                s=16,\n",
    "            ),\n",
    "            ax=axs['21']\n",
    "        )\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_imm_curr,\n",
    "        x='Group',\n",
    "        y=feat,\n",
    "        hue='Group',\n",
    "        palette=colors_samples_groups,\n",
    "        density_norm='width',\n",
    "        order=['Central', 'Mirny', 'FMBA'],\n",
    "        saturation=0.75,\n",
    "        linewidth=1.0,\n",
    "        ax=axs['22'],\n",
    "        legend=False,\n",
    "        cut=0,\n",
    "    )\n",
    "    axs['22'].set_ylabel(feat)\n",
    "    axs['22'].set_xlabel(\"\")\n",
    "\n",
    "fig.savefig(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/feats.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"{path}/01_new_data_05_2025/different_groups_in_new_data/feats.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
