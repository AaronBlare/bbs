{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Debugging autoreload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pytorch_tabular.utils import load_covertype_dataset\n",
    "from rich.pretty import pprint\n",
    "from sklearn.model_selection import BaseCrossValidator, ParameterGrid, ParameterSampler\n",
    "import torch\n",
    "import pickle\n",
    "import shap\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from glob import glob\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "import pandas as pd\n",
    "from pytorch_tabular import model_sweep\n",
    "from src.pt.model_sweep import model_sweep_custom\n",
    "import warnings\n",
    "from src.utils.configs import read_parse_config\n",
    "from src.utils.hash import dict_hash\n",
    "from src.pt.hyper_opt import train_hyper_opt\n",
    "import optuna\n",
    "import pathlib\n",
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*exists and is not empty.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*is smaller than the logging interval Trainer.*\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load immunomarkers models"
  },
  {
   "cell_type": "code",
   "source": [
    "feats_imm = pd.read_excel(f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/059_imm_data_selection/feats_selected.xlsx\", index_col=0).index.values\n",
    "\n",
    "epi_data_type = 'no_harm'\n",
    "imm_data_type = 'imp_source(imm)_method(knn)_params(5)' # 'origin' 'imp_source(imm)_method(knn)_params(5)' 'imp_source(imm)_method(miceforest)_params(2)'\n",
    "\n",
    "selection_method = 'mrmr' # 'f_regression' 'spearman' 'mrmr'\n",
    "n_feats = 100\n",
    "\n",
    "path_imm = f\"D:/YandexDisk/Work/bbd/immunology/003_EpImAge/{imm_data_type}/{epi_data_type}/{selection_method}_{n_feats}\"\n",
    "path_save = f\"{path_imm}/EpImAge\"\n",
    "pathlib.Path(path_save).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_models = pd.read_excel(f\"{path_imm}/best_models_v3.xlsx\", index_col=0)\n",
    "                \n",
    "imm_epi_feats = {}              \n",
    "imm_models = {}\n",
    "for imm in (pbar := tqdm(feats_imm)):\n",
    "    pbar.set_description(f\"Processing {imm}\")\n",
    "    imm_epi_feats[imm] = pd.read_excel(f\"{path_imm}/{imm}/feats_con.xlsx\", index_col=0).index.values.tolist()\n",
    "    imm_path_model = f\"{path_imm}/{imm}/pytorch_tabular/candidates/{df_models.at[imm, 'model']}/{df_models.at[imm, 'directory']}/model.ckpt\"\n",
    "    head, tail = os.path.split(imm_path_model)\n",
    "    imm_models[imm] = TabularModel.load_model(f\"{head}\")\n",
    "\n",
    "feats_epi_cmn = list(set.union(*[set(x) for x in imm_epi_feats.values()]))\n",
    "print(f\"Number of CpGs: {len(feats_epi_cmn)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load epigenetics data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path_epi = \"D:/YandexDisk/Work/bbd/immunology/003_EpImAge/epi\"\n",
    "feats_pheno = ['Age', 'Sex', 'Status', 'Tissue']\n",
    "gpls = [f.name for f in os.scandir(path_epi) if f.is_dir()]\n",
    "gse_missed_cpgs = {}\n",
    "dfs = []\n",
    "for gpl in gpls:\n",
    "    print(gpl)\n",
    "    gses = [f.name for f in os.scandir(f\"{path_epi}/{gpl}\") if f.is_dir()]\n",
    "    for gse in (pbar := tqdm(gses)):\n",
    "        pbar.set_description(f\"Processing {gse}\")\n",
    "        if gse == 'GSEUNN':\n",
    "            df_betas = pd.read_pickle(f\"{path_epi}/{gpl}/{gse}/{epi_data_type}/betas.pkl\")\n",
    "            df_pheno = pd.read_csv(f\"{path_epi}/{gpl}/{gse}/{epi_data_type}/pheno.csv\", index_col='index')\n",
    "        elif gse == 'GSE53740':\n",
    "            df_betas = pd.read_pickle(f\"{path_epi}/{gpl}/{gse}/betas.pkl\")\n",
    "            df_pheno = pd.read_csv(f\"{path_epi}/{gpl}/{gse}/pheno.csv\", index_col=0)\n",
    "            df_pheno.drop(df_pheno.index[df_pheno['Status'] == 'Unknown'], inplace=True)\n",
    "        elif gse == 'GSE87648':\n",
    "            df_betas = pd.read_pickle(f\"{path_epi}/{gpl}/{gse}/betas.pkl\")\n",
    "            df_pheno = pd.read_csv(f\"{path_epi}/{gpl}/{gse}/pheno.csv\", index_col=0)\n",
    "            df_pheno.drop(df_pheno.index[df_pheno['Status'] == 'HS'], inplace=True)\n",
    "        else:\n",
    "            df_betas = pd.read_pickle(f\"{path_epi}/{gpl}/{gse}/betas.pkl\")\n",
    "            df_pheno = pd.read_csv(f\"{path_epi}/{gpl}/{gse}/pheno.csv\", index_col=0)\n",
    "        gse_missed_cpgs[gse] = len(set(feats_epi_cmn) - set(df_betas.columns))\n",
    "        exist_cpgs = list(set.intersection(set(df_betas.columns), set(feats_epi_cmn)))\n",
    "        df = pd.merge(df_pheno.loc[:, feats_pheno], df_betas.loc[:, exist_cpgs], left_index=True, right_index=True)\n",
    "        df.insert(0, 'GPL', gpl)\n",
    "        df.insert(0, 'GSE', gse)\n",
    "        dfs.append(df)\n",
    "        \n",
    "df_gse_missed_cpgs = pd.DataFrame.from_dict(gse_missed_cpgs, orient='index', columns=['Missed CpGs'])\n",
    "df_gse_missed_cpgs.to_excel(f\"{path_save}/gse_missed_cpgs.xlsx\", index=True, index_label='GSE')\n",
    "\n",
    "df = pd.concat(dfs, verify_integrity=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Impute missing values"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_neighbors = 5\n",
    "X = df.loc[:, feats_epi_cmn + ['Age']].values\n",
    "print(f'Missing before imputation: {np.isnan(X).sum()}')\n",
    "imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "X_imptd = imputer.fit_transform(X)\n",
    "print(f'Missing after imputation: {np.isnan(X_imptd).sum()}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.loc[:, feats_epi_cmn + ['Age']] = X_imptd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate immunomarkers"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for imm in (pbar := tqdm(feats_imm)):\n",
    "    pbar.set_description(f\"Processing {imm}\")\n",
    "    df[f\"{imm}_log\"] = imm_models[imm].predict(df.loc[:, imm_epi_feats[imm]])\n",
    "    df[imm] = np.exp(df[f\"{imm}_log\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[['GPL', 'GSE'] + feats_pheno + list(feats_imm) + [f\"{imm}_log\" for imm in feats_imm]].to_excel(f\"{path_save}/data.xlsx\")\n",
    "df.to_pickle(f\"{path_save}/data_full.pkl\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check models on GSEUNN"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tst_n_splits = 5\n",
    "tst_n_repeats = 5\n",
    "tst_random_state = 1337\n",
    "tst_split_id = 5\n",
    "\n",
    "val_n_splits = 4\n",
    "val_n_repeats = 2\n",
    "val_random_state = 1337\n",
    "val_fold_id = 5\n",
    "\n",
    "fn_samples = f\"samples_tst({tst_random_state}_{tst_n_splits}_{tst_n_repeats})_val({val_random_state}_{val_n_splits}_{val_n_repeats})\"\n",
    "with open(f\"D:/YandexDisk/Work/bbd/immunology/003_EpImAge/{fn_samples}.pickle\", 'rb') as handle:\n",
    "    samples = pickle.load(handle)\n",
    "    \n",
    "for split_id in range(tst_n_splits * tst_n_repeats):\n",
    "    for fold_id in range(val_n_splits * val_n_repeats):\n",
    "        test_samples = samples[split_id]['test']\n",
    "        train_samples = samples[split_id]['trains'][fold_id]\n",
    "        validation_samples = samples[split_id]['validations'][fold_id]\n",
    "\n",
    "        intxns = {\n",
    "            'train_validation': set.intersection(set(train_samples), set(validation_samples)),\n",
    "            'validation_test': set.intersection(set(validation_samples), set(test_samples)),\n",
    "            'train_test': set.intersection(set(train_samples), set(test_samples))\n",
    "        }\n",
    "\n",
    "        for intxn_name, intxn_samples in intxns.items():\n",
    "            if len(intxn_samples) > 0:\n",
    "                print(f\"Non-zero {intxn_name} intersection ({len(intxn_samples)}) for {split_id} Split and {fold_id} Fold!\")\n",
    "\n",
    "split_dict = samples[tst_split_id]\n",
    "\n",
    "df_models_check = pd.DataFrame(index=feats_imm)\n",
    "for imm in (pbar := tqdm(feats_imm)):\n",
    "    pbar.set_description(f\"Processing {imm}\")\n",
    "    data_imm = pd.read_excel(f\"{path_imm}/{imm}/data.xlsx\", index_col=0)\n",
    "    \n",
    "    y_train_real = torch.from_numpy(data_imm.loc[split_dict['trains'][val_fold_id], f\"{imm}_log\"].values)\n",
    "    y_validation_real = torch.from_numpy(data_imm.loc[split_dict['validations'][val_fold_id], f\"{imm}_log\"].values)\n",
    "    y_test_real = torch.from_numpy(data_imm.loc[split_dict['test'], f\"{imm}_log\"].values)\n",
    "    \n",
    "    y_train_pred = torch.from_numpy(df.loc[split_dict['trains'][val_fold_id], f\"{imm}_log\"].values)\n",
    "    y_validation_pred = torch.from_numpy(df.loc[split_dict['validations'][val_fold_id], f\"{imm}_log\"].values)\n",
    "    y_test_pred = torch.from_numpy(df.loc[split_dict['test'], f\"{imm}_log\"].values)\n",
    "    \n",
    "    df_models_check.at[imm, 'train_mae_before'] = df_models.at[imm, 'train_mean_absolute_error']\n",
    "    df_models_check.at[imm, 'validation_mae_before'] = df_models.at[imm, 'validation_mean_absolute_error']\n",
    "    df_models_check.at[imm, 'test_mae_before'] = df_models.at[imm, 'test_mean_absolute_error']\n",
    "    df_models_check.at[imm, 'train_mae_after'] = mean_absolute_error(y_train_pred, y_train_real).numpy()\n",
    "    df_models_check.at[imm, 'validation_mae_after'] = mean_absolute_error(y_validation_pred, y_validation_real).numpy()\n",
    "    df_models_check.at[imm, 'test_mae_after'] = mean_absolute_error(y_test_pred, y_test_real).numpy()\n",
    "    \n",
    "    df_models_check.at[imm, 'train_rho_before'] = df_models.at[imm, 'train_pearson_corrcoef']\n",
    "    df_models_check.at[imm, 'validation_rho_before'] = df_models.at[imm, 'validation_pearson_corrcoef']\n",
    "    df_models_check.at[imm, 'test_rho_before'] = df_models.at[imm, 'test_pearson_corrcoef']\n",
    "    df_models_check.at[imm, 'train_rho_after'] = pearson_corrcoef(y_train_pred, y_train_real).numpy()\n",
    "    df_models_check.at[imm, 'validation_rho_after'] = pearson_corrcoef(y_validation_pred, y_validation_real).numpy()\n",
    "    df_models_check.at[imm, 'test_rho_after'] = pearson_corrcoef(y_test_pred, y_test_real).numpy()\n",
    "\n",
    "df_models_check['train_mae_diff'] = df_models_check['train_mae_after'] - df_models_check['train_mae_before']\n",
    "df_models_check['validation_mae_diff'] = df_models_check['validation_mae_after'] - df_models_check['validation_mae_before']\n",
    "df_models_check['test_mae_diff'] = df_models_check['test_mae_after'] - df_models_check['test_mae_before']\n",
    "\n",
    "df_models_check['train_rho_diff'] = df_models_check['train_rho_after'] - df_models_check['train_rho_before']\n",
    "df_models_check['validation_rho_diff'] = df_models_check['validation_rho_after'] - df_models_check['validation_rho_before']\n",
    "df_models_check['test_rho_diff'] = df_models_check['test_rho_after'] - df_models_check['test_rho_before']\n",
    "\n",
    "df_models_check.to_excel(f\"{path_save}/models_check.xlsx\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
