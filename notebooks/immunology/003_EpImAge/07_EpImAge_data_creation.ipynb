{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pytorch_tabular import TabularModel\n",
    "from torchmetrics.functional.regression import mean_absolute_error, pearson_corrcoef\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pathlib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import KNNImputer\n",
    "import pyaging as pya\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import distinctipy\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patheffects as pe\n",
    "from plottable import ColumnDefinition, Table\n",
    "from plottable.cmap import normed_cmap\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*exists and is not empty.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*is smaller than the logging interval Trainer.*\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup variables and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats_imm = pd.read_excel(f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/059_imm_data_selection/feats_selected.xlsx\", index_col=0).index.values\n",
    "\n",
    "epi_data_type = 'no_harm'\n",
    "imm_data_type = 'imp_source(imm)_method(knn)_params(5)' # 'origin' 'imp_source(imm)_method(knn)_params(5)' 'imp_source(imm)_method(miceforest)_params(2)'\n",
    "\n",
    "selection_method = 'mrmr' # 'f_regression' 'spearman' 'mrmr'\n",
    "n_feats = 100\n",
    "\n",
    "path_imm = f\"D:/YandexDisk/Work/bbd/immunology/003_EpImAge/{imm_data_type}/{epi_data_type}/{selection_method}_{n_feats}\"\n",
    "path_save = f\"{path_imm}/EpImAge\"\n",
    "pathlib.Path(path_save).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_models = pd.read_excel(f\"{path_imm}/best_models_v4.xlsx\", index_col=0)\n",
    "\n",
    "path_epi = \"D:/YandexDisk/Work/bbd/immunology/003_EpImAge/epi\"\n",
    "feats_pheno = ['Age', 'Sex', 'Status', 'Tissue']\n",
    "path_clocks = \"D:/YandexDisk/Work/pydnameth/datasets/pyaging\"\n",
    "clocks = [\n",
    "    \"altumage\",\n",
    "    \"dunedinpace\",\n",
    "    \"han\",\n",
    "    \"knight\",\n",
    "    \"leecontrol\",\n",
    "    \"leerefinedrobust\",\n",
    "    \"leerobust\",\n",
    "    \"dnamfitage\",\n",
    "    \"dnamphenoage\",\n",
    "    \"dnamtl\",\n",
    "    \"encen100\",\n",
    "    \"encen40\",\n",
    "    \"grimage\",\n",
    "    \"grimage2\",\n",
    "    \"hannum\",\n",
    "    \"horvath2013\",\n",
    "    \"hrsinchphenoage\",\n",
    "    \"lin\",\n",
    "    \"pcdnamtl\",\n",
    "    \"pcgrimage\",\n",
    "    \"pchannum\",\n",
    "    \"pchorvath2013\",\n",
    "    \"pcphenoage\",\n",
    "    \"pcskinandblood\",\n",
    "    \"pedbe\",\n",
    "    \"replitali\",\n",
    "    \"skinandblood\",\n",
    "    \"stemtoc\",\n",
    "    \"stoch\",\n",
    "    \"stocp\",\n",
    "    \"stocz\",\n",
    "    \"yingadaptage\",\n",
    "    \"yingcausage\",\n",
    "    \"yingdamage\",\n",
    "    \"zhangblup\",\n",
    "    \"zhangen\",\n",
    "    \"zhangmortality\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load immunomarkers models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_epi_feats = {}              \n",
    "imm_models = {}\n",
    "for imm in (pbar := tqdm(feats_imm)):\n",
    "    pbar.set_description(f\"Processing {imm}\")\n",
    "    imm_epi_feats[imm] = pd.read_excel(f\"{path_imm}/{imm}/feats_con.xlsx\", index_col=0).index.values.tolist()\n",
    "    imm_path_model = f\"{path_imm}/{imm}/pytorch_tabular/candidates/{df_models.at[imm, 'model']}/{df_models.at[imm, 'directory']}/model.ckpt\"\n",
    "    head, tail = os.path.split(imm_path_model)\n",
    "    imm_models[imm] = TabularModel.load_model(f\"{head}\")\n",
    "\n",
    "feats_epi_cmn = list(set.union(*[set(x) for x in imm_epi_feats.values()]))\n",
    "print(f\"Number of CpGs: {len(feats_epi_cmn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load epigenetics data and calculate clocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpls = [f.name for f in os.scandir(path_epi) if f.is_dir()]\n",
    "gse_missed_cpgs = {}\n",
    "dfs_gses = []\n",
    "for gpl in gpls:\n",
    "    print(gpl)\n",
    "    gses = [f.name for f in os.scandir(f\"{path_epi}/{gpl}\") if f.is_dir()]\n",
    "    for gse in (pbar := tqdm(gses)):\n",
    "        pbar.set_description(f\"Processing {gse}\")\n",
    "        if gse == 'GSEUNN':\n",
    "            df_betas = pd.read_pickle(f\"{path_epi}/{gpl}/{gse}/{epi_data_type}/betas.pkl\")\n",
    "            df_pheno = pd.read_csv(f\"{path_epi}/{gpl}/{gse}/{epi_data_type}/pheno.csv\", index_col='index')\n",
    "        elif gse == 'GSE53740':\n",
    "            df_betas = pd.read_pickle(f\"{path_epi}/{gpl}/{gse}/betas.pkl\")\n",
    "            df_pheno = pd.read_csv(f\"{path_epi}/{gpl}/{gse}/pheno.csv\", index_col=0)\n",
    "            df_pheno.drop(df_pheno.index[df_pheno['Status'] == 'Unknown'], inplace=True)\n",
    "        elif gse == 'GSE87648':\n",
    "            df_betas = pd.read_pickle(f\"{path_epi}/{gpl}/{gse}/betas.pkl\")\n",
    "            df_pheno = pd.read_csv(f\"{path_epi}/{gpl}/{gse}/pheno.csv\", index_col=0)\n",
    "            df_pheno.drop(df_pheno.index[df_pheno['Status'] == 'HS'], inplace=True)\n",
    "        else:\n",
    "            df_betas = pd.read_pickle(f\"{path_epi}/{gpl}/{gse}/betas.pkl\")\n",
    "            df_pheno = pd.read_csv(f\"{path_epi}/{gpl}/{gse}/pheno.csv\", index_col='gsm')\n",
    "        df_for_ages = pd.merge(df_pheno.loc[:, feats_pheno], df_betas, left_index=True, right_index=True)\n",
    "        if df_for_ages['Sex'].value_counts().size > 2:\n",
    "            raise ValueError(f\"More than 2 sexes\")\n",
    "        elif df_for_ages['Sex'].value_counts().size == 1:\n",
    "            print(f\"{gse} contains only one sex\")\n",
    "        else:\n",
    "            print(f\"{gse} contains 2 sexes\")\n",
    "        df_for_ages['Female'] = (df_for_ages['Sex'] == 'F').astype(int)\n",
    "        df_for_ages = pya.pp.epicv2_probe_aggregation(df_for_ages, verbose=False)\n",
    "        adata = pya.pp.df_to_adata(df_for_ages, metadata_cols=['Sex', 'Status', 'Tissue'], imputer_strategy='knn', verbose=False)\n",
    "        pya.pred.predict_age(adata=adata, dir=path_clocks, clock_names=clocks, verbose=False)\n",
    "        df_pheno = pd.merge(df_pheno.loc[:, feats_pheno], adata.obs[clocks], left_index=True, right_index=True)\n",
    "        gse_missed_cpgs[gse] = len(set(feats_epi_cmn) - set(df_betas.columns))\n",
    "        exist_cpgs = list(set.intersection(set(df_betas.columns), set(feats_epi_cmn)))\n",
    "        df_gse = pd.merge(df_pheno, df_betas.loc[:, exist_cpgs], left_index=True, right_index=True)\n",
    "        if df_gse.shape[0] == 0:\n",
    "            raise ValueError(f\"{gse} indexes problem!\")\n",
    "        df_gse.insert(0, 'GPL', gpl)\n",
    "        df_gse.insert(0, 'GSE', gse)\n",
    "        dfs_gses.append(df_gse)\n",
    "        \n",
    "df_gse_missed_cpgs = pd.DataFrame.from_dict(gse_missed_cpgs, orient='index', columns=['Missed CpGs'])\n",
    "df_gse_missed_cpgs.to_excel(f\"{path_save}/gse_missed_cpgs.xlsx\", index=True, index_label='GSE')\n",
    "\n",
    "df = pd.concat(dfs_gses, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 5\n",
    "X = df.loc[:, feats_epi_cmn + ['Age']].values\n",
    "print(f'Missing before imputation: {np.isnan(X).sum()}')\n",
    "imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "X_imptd = imputer.fit_transform(X)\n",
    "print(f'Missing after imputation: {np.isnan(X_imptd).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, feats_epi_cmn + ['Age']] = X_imptd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate immunomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imm in (pbar := tqdm(feats_imm)):\n",
    "    pbar.set_description(f\"Processing {imm}\")\n",
    "    df[f\"{imm}_log\"] = imm_models[imm].predict(df.loc[:, imm_epi_feats[imm]])\n",
    "    df[imm] = np.exp(df[f\"{imm}_log\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['GPL', 'GSE'] + feats_pheno + clocks + list(feats_imm) + [f\"{imm}_log\" for imm in feats_imm]].to_excel(f\"{path_save}/data.xlsx\")\n",
    "df.to_pickle(f\"{path_save}/data_full.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check models on GSEUNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_n_splits = 5\n",
    "tst_n_repeats = 5\n",
    "tst_random_state = 1337\n",
    "tst_split_id = 5\n",
    "\n",
    "val_n_splits = 4\n",
    "val_n_repeats = 2\n",
    "val_random_state = 1337\n",
    "val_fold_id = 5\n",
    "\n",
    "fn_samples = f\"samples_tst({tst_random_state}_{tst_n_splits}_{tst_n_repeats})_val({val_random_state}_{val_n_splits}_{val_n_repeats})\"\n",
    "with open(f\"D:/YandexDisk/Work/bbd/immunology/003_EpImAge/{fn_samples}.pickle\", 'rb') as handle:\n",
    "    samples = pickle.load(handle)\n",
    "    \n",
    "for split_id in range(tst_n_splits * tst_n_repeats):\n",
    "    for fold_id in range(val_n_splits * val_n_repeats):\n",
    "        test_samples = samples[split_id]['test']\n",
    "        train_samples = samples[split_id]['trains'][fold_id]\n",
    "        validation_samples = samples[split_id]['validations'][fold_id]\n",
    "\n",
    "        intxns = {\n",
    "            'train_validation': set.intersection(set(train_samples), set(validation_samples)),\n",
    "            'validation_test': set.intersection(set(validation_samples), set(test_samples)),\n",
    "            'train_test': set.intersection(set(train_samples), set(test_samples))\n",
    "        }\n",
    "\n",
    "        for intxn_name, intxn_samples in intxns.items():\n",
    "            if len(intxn_samples) > 0:\n",
    "                print(f\"Non-zero {intxn_name} intersection ({len(intxn_samples)}) for {split_id} Split and {fold_id} Fold!\")\n",
    "\n",
    "split_dict = samples[tst_split_id]\n",
    "\n",
    "df_models_check = pd.DataFrame(index=feats_imm)\n",
    "for imm in (pbar := tqdm(feats_imm)):\n",
    "    pbar.set_description(f\"Processing {imm}\")\n",
    "    data_imm = pd.read_excel(f\"{path_imm}/{imm}/data.xlsx\", index_col=0)\n",
    "    \n",
    "    y_train_real = torch.from_numpy(data_imm.loc[split_dict['trains'][val_fold_id], f\"{imm}_log\"].values)\n",
    "    y_validation_real = torch.from_numpy(data_imm.loc[split_dict['validations'][val_fold_id], f\"{imm}_log\"].values)\n",
    "    y_test_real = torch.from_numpy(data_imm.loc[split_dict['test'], f\"{imm}_log\"].values)\n",
    "    \n",
    "    y_train_pred = torch.from_numpy(df.loc[split_dict['trains'][val_fold_id], f\"{imm}_log\"].values)\n",
    "    y_validation_pred = torch.from_numpy(df.loc[split_dict['validations'][val_fold_id], f\"{imm}_log\"].values)\n",
    "    y_test_pred = torch.from_numpy(df.loc[split_dict['test'], f\"{imm}_log\"].values)\n",
    "    \n",
    "    df_models_check.at[imm, 'train_mae_before'] = df_models.at[imm, 'train_mean_absolute_error']\n",
    "    df_models_check.at[imm, 'validation_mae_before'] = df_models.at[imm, 'validation_mean_absolute_error']\n",
    "    df_models_check.at[imm, 'test_mae_before'] = df_models.at[imm, 'test_mean_absolute_error']\n",
    "    df_models_check.at[imm, 'train_mae_after'] = mean_absolute_error(y_train_pred, y_train_real).numpy()\n",
    "    df_models_check.at[imm, 'validation_mae_after'] = mean_absolute_error(y_validation_pred, y_validation_real).numpy()\n",
    "    df_models_check.at[imm, 'test_mae_after'] = mean_absolute_error(y_test_pred, y_test_real).numpy()\n",
    "    \n",
    "    df_models_check.at[imm, 'train_rho_before'] = df_models.at[imm, 'train_pearson_corrcoef']\n",
    "    df_models_check.at[imm, 'validation_rho_before'] = df_models.at[imm, 'validation_pearson_corrcoef']\n",
    "    df_models_check.at[imm, 'test_rho_before'] = df_models.at[imm, 'test_pearson_corrcoef']\n",
    "    df_models_check.at[imm, 'train_rho_after'] = pearson_corrcoef(y_train_pred, y_train_real).numpy()\n",
    "    df_models_check.at[imm, 'validation_rho_after'] = pearson_corrcoef(y_validation_pred, y_validation_real).numpy()\n",
    "    df_models_check.at[imm, 'test_rho_after'] = pearson_corrcoef(y_test_pred, y_test_real).numpy()\n",
    "\n",
    "df_models_check['train_mae_diff'] = df_models_check['train_mae_after'] - df_models_check['train_mae_before']\n",
    "df_models_check['validation_mae_diff'] = df_models_check['validation_mae_after'] - df_models_check['validation_mae_before']\n",
    "df_models_check['test_mae_diff'] = df_models_check['test_mae_after'] - df_models_check['test_mae_before']\n",
    "\n",
    "df_models_check['train_rho_diff'] = df_models_check['train_rho_after'] - df_models_check['train_rho_before']\n",
    "df_models_check['validation_rho_diff'] = df_models_check['validation_rho_after'] - df_models_check['validation_rho_before']\n",
    "df_models_check['test_rho_diff'] = df_models_check['test_rho_after'] - df_models_check['test_rho_before']\n",
    "\n",
    "df_models_check.to_excel(f\"{path_save}/models_check.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot immunomarkers results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(f\"{path_save}/data.xlsx\", index_col=0)\n",
    "df_models.sort_values(['test_pearson_corrcoef'], ascending=[False], inplace=True)\n",
    "       \n",
    "imm_results = {}\n",
    "for imm, row in (pbar := tqdm(df_models.iterrows())):\n",
    "    pbar.set_description(f\"Processing {imm}\")\n",
    "    imm_result = pd.read_excel(f\"{path_imm}/{imm}/pytorch_tabular/candidates/{row['model']}/{row['directory']}/df.xlsx\", index_col=0)\n",
    "    imm_result.rename(columns={f\"{imm}_log\": imm}, inplace=True)\n",
    "    imm_results[imm] = imm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 4 * 3\n",
    "n_cols = 8\n",
    "fig_height = 20\n",
    "fig_width = 35\n",
    "\n",
    "imm_colors = distinctipy.get_colors(n_colors=df_models.shape[0], exclude_colors=[mcolors.hex2color(mcolors.CSS4_COLORS['gray'])], rng=42)\n",
    "\n",
    "sns.set_theme(style='ticks')\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height), height_ratios=[0.2, 0.8, 0.2]*4, gridspec_kw={'wspace':0.35, 'hspace': 0.05}, sharey=False, sharex=False)\n",
    "\n",
    "for imm_id, imm in tqdm(enumerate(df_models.index.values)):\n",
    "    imm_color = imm_colors[imm_id]\n",
    "    imm_result = imm_results[imm]\n",
    "    row_id, col_id = divmod(imm_id, n_cols)\n",
    "    row_id_table = row_id * 3\n",
    "    row_id_scatter = row_id * 3 + 1\n",
    "    row_id_empty = row_id * 3 + 2\n",
    "\n",
    "    q01 = imm_result[imm].quantile(0.01)\n",
    "    q99 = imm_result[imm].quantile(0.99)\n",
    "\n",
    "    df_metrics = pd.DataFrame(index=['MAE', fr\"Pearson $\\mathbf{{\\rho}}$\"], columns=['Train', 'Validation', 'Test'])\n",
    "    df_metrics.at['MAE', 'Train'] = f\"{df_models.at[imm, 'train_mean_absolute_error']:0.3f}\"\n",
    "    df_metrics.at['MAE', 'Validation'] = f\"{df_models.at[imm, 'validation_mean_absolute_error']:0.3f}\"\n",
    "    df_metrics.at['MAE', 'Test'] = f\"{df_models.at[imm, 'test_mean_absolute_error']:0.3f}\"\n",
    "    df_metrics.at[fr\"Pearson $\\mathbf{{\\rho}}$\", 'Train'] = f\"{df_models.at[imm, 'train_pearson_corrcoef']:0.3f}\"\n",
    "    df_metrics.at[fr\"Pearson $\\mathbf{{\\rho}}$\", 'Validation'] = f\"{df_models.at[imm, 'validation_pearson_corrcoef']:0.3f}\"\n",
    "    df_metrics.at[fr\"Pearson $\\mathbf{{\\rho}}$\", 'Test'] = f\"{df_models.at[imm, 'test_pearson_corrcoef']:0.3f}\"\n",
    "    \n",
    "    col_defs = [\n",
    "        ColumnDefinition(\n",
    "            name=\"index\",\n",
    "            title=imm,\n",
    "            textprops={\"ha\": \"center\", \"weight\": \"bold\"},\n",
    "            width=2.5,\n",
    "            # border=\"both\"\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Train\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "            border=\"left\"\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Validation\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "            # border=\"both\"\n",
    "        ),\n",
    "        ColumnDefinition(\n",
    "            name=\"Test\",\n",
    "            textprops={\"ha\": \"left\"},\n",
    "            width=1.5,\n",
    "            # border=\"both\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    table = Table(\n",
    "        df_metrics,\n",
    "        column_definitions=col_defs,\n",
    "        row_dividers=True,\n",
    "        footer_divider=False,\n",
    "        ax=axs[row_id_table, col_id],\n",
    "        textprops={\"fontsize\": 8},\n",
    "        row_divider_kw={\"linewidth\": 1, \"linestyle\": (0, (1, 1))},\n",
    "        col_label_divider_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "        column_border_kw={\"linewidth\": 1, \"linestyle\": \"-\"},\n",
    "    ).autoset_fontcolors(colnames=['Train', 'Validation', 'Test'])\n",
    "\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=imm_result.loc[imm_result['Group'] != 'Test', :],\n",
    "        x=imm,\n",
    "        y='Prediction',\n",
    "        fill=True,\n",
    "        cbar=False,\n",
    "        color='gray',\n",
    "        cut=0,\n",
    "        legend=False,\n",
    "        ax=axs[row_id_scatter, col_id]\n",
    "    )\n",
    "    scatter = sns.scatterplot(\n",
    "        data=imm_result.loc[imm_result['Group'] == 'Test', :],\n",
    "        x=imm,\n",
    "        y=\"Prediction\",\n",
    "        linewidth=0.5,\n",
    "        alpha=0.8,\n",
    "        edgecolor=\"k\",\n",
    "        s=35,\n",
    "        color=imm_color,\n",
    "        ax=axs[row_id_scatter, col_id],\n",
    "    )\n",
    "    axs[row_id_scatter, col_id].axline((0, 0), slope=1, color=\"black\", linestyle=\":\")\n",
    "    axs[row_id_scatter, col_id].set_xlim(q01, q99)\n",
    "    axs[row_id_scatter, col_id].set_ylim(q01, q99)\n",
    "    axs[row_id_scatter, col_id].set_xlabel(imm, color=imm_color, path_effects=[pe.withStroke(linewidth=1.0, foreground=\"black\")])\n",
    "    \n",
    "    axs[row_id_empty, col_id].axis('off')\n",
    "\n",
    "fig.tight_layout()    \n",
    "fig.savefig(f\"{path_save}/immuno.png\", bbox_inches='tight', dpi=200)\n",
    "fig.savefig(f\"{path_save}/immuno.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data for additional statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSE statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(f\"{path_save}/data.xlsx\", index_col=0)\n",
    "gse_count = data['GSE'].value_counts()\n",
    "gse_count.to_excel(f\"{path_save}/gse_preproc.xlsx\", index_label='GSE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
